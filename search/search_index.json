{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"pyNMMS","text":"<p>An automated reasoner for the Non-Monotonic Multi-Succedent (NMMS) propositional sequent calculus from Hlobil &amp; Brandom 2025, Ch. 3.</p> <p>pyNMMS implements a proof search engine for the NMMS sequent calculus, which codifies open reason relations \u2014 consequence relations where Monotonicity and Transitivity can fail.</p>"},{"location":"#why-pynmms","title":"Why pyNMMS?","text":"<p>Traditional logics assume that adding premises never defeats an inference (Monotonicity) and that chaining good inferences always yields good inferences (Transitivity). But real-world reasoning is often defeasible: new information can override previous conclusions.</p> <p>pyNMMS provides:</p> <ul> <li>A material base for encoding defeasible inferences among atomic sentences</li> <li>Backward proof search implementing all 8 propositional NMMS rules</li> <li>Supraclassicality: all classically valid sequents remain derivable</li> <li>A Tell/Ask CLI and interactive REPL for exploring reason relations</li> <li>Full proof traces for understanding derivations</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from pynmms import MaterialBase, NMMSReasoner\n\nbase = MaterialBase(\n    language={\"A\", \"B\", \"C\"},\n    consequences={\n        (frozenset({\"A\"}), frozenset({\"B\"})),  # A |~ B\n        (frozenset({\"B\"}), frozenset({\"C\"})),  # B |~ C\n    },\n)\nreasoner = NMMSReasoner(base)\n\nreasoner.query(frozenset({\"A\"}), frozenset({\"B\"}))  # True (base consequence)\nreasoner.query(frozenset({\"A\"}), frozenset({\"C\"}))  # False (nontransitive!)\nreasoner.query(frozenset({\"A\", \"C\"}), frozenset({\"B\"}))  # False (nonmonotonic!)\nreasoner.query(frozenset(), frozenset({\"A | ~A\"}))  # True (supraclassical)\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pyNMMS\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<pre><code>pip install pyNMMS\n</code></pre> <p>For development:</p> <pre><code>git clone https://github.com/bradleyallen/nmms-reasoner.git\ncd nmms-reasoner\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/#your-first-material-base","title":"Your First Material Base","text":"<p>A material base encodes defeasible material inferences among atomic sentences.</p> <pre><code>from pynmms import MaterialBase, NMMSReasoner\n\n# Create a base: \"rain\" defeasibly implies \"wet ground\"\nbase = MaterialBase(\n    language={\"rain\", \"wet_ground\", \"covered\"},\n    consequences={\n        (frozenset({\"rain\"}), frozenset({\"wet_ground\"})),\n    },\n)\n</code></pre>"},{"location":"getting-started/#querying-derivability","title":"Querying Derivability","text":"<pre><code>reasoner = NMMSReasoner(base)\n\n# Does rain derive wet ground?\nresult = reasoner.derives(frozenset({\"rain\"}), frozenset({\"wet_ground\"}))\nprint(result.derivable)  # True\n\n# Nonmonotonicity: adding \"covered\" defeats the inference\nresult = reasoner.derives(\n    frozenset({\"rain\", \"covered\"}),\n    frozenset({\"wet_ground\"})\n)\nprint(result.derivable)  # False \u2014 no weakening!\n</code></pre>"},{"location":"getting-started/#using-the-cli","title":"Using the CLI","text":"<pre><code># Create a base\npynmms tell -b mybase.json --create \"rain |~ wet_ground\"\n\n# Query it\npynmms ask -b mybase.json \"rain =&gt; wet_ground\"        # DERIVABLE\npynmms ask -b mybase.json \"rain, covered =&gt; wet_ground\"  # NOT DERIVABLE\n\n# Interactive REPL\npynmms repl -b mybase.json\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Key Concepts \u2014 understand material bases, nonmonotonicity, and sequents</li> <li>Proof Search \u2014 how the reasoner works and how to read traces</li> <li>CLI Usage \u2014 full guide to the Tell/Ask CLI and REPL</li> </ul>"},{"location":"api/base/","title":"MaterialBase","text":""},{"location":"api/base/#pynmms.base.MaterialBase","title":"<code>pynmms.base.MaterialBase</code>  <code>dataclass</code>","text":"<p>A material base B =  for propositional NMMS. <p>Parameters:</p> Name Type Description Default <code>language</code> <code>set[str] | frozenset[str] | None</code> <p>Set of atomic sentence strings comprising L_B.</p> <code>None</code> <code>consequences</code> <code>set[Sequent] | set[tuple[frozenset[str], frozenset[str]]] | None</code> <p>Set of (antecedent, consequent) sequent pairs comprising |~_B.</p> <code>None</code> Source code in <code>src/pynmms/base.py</code> <pre><code>@dataclass\nclass MaterialBase:\n    \"\"\"A material base B = &lt;L_B, |~_B&gt; for propositional NMMS.\n\n    Parameters:\n        language: Set of atomic sentence strings comprising L_B.\n        consequences: Set of (antecedent, consequent) sequent pairs comprising |~_B.\n    \"\"\"\n\n    _language: set[str] = field(default_factory=set)\n    _consequences: set[Sequent] = field(default_factory=set)\n\n    def __init__(\n        self,\n        language: set[str] | frozenset[str] | None = None,\n        consequences: (\n            set[Sequent]\n            | set[tuple[frozenset[str], frozenset[str]]]\n            | None\n        ) = None,\n    ) -&gt; None:\n        self._language: set[str] = set(language) if language else set()\n        self._consequences: set[Sequent] = set()\n\n        # Validate all language atoms\n        for s in self._language:\n            _validate_atomic(s, \"Material base language\")\n\n        # Validate and store consequences\n        if consequences:\n            for gamma, delta in consequences:\n                for s in gamma | delta:\n                    _validate_atomic(s, \"Material base consequence\")\n                self._consequences.add((gamma, delta))\n\n        logger.debug(\n            \"MaterialBase created: %d atoms, %d consequences\",\n            len(self._language),\n            len(self._consequences),\n        )\n\n    # --- Read-only properties ---\n\n    @property\n    def language(self) -&gt; frozenset[str]:\n        \"\"\"The atomic language L_B (read-only view).\"\"\"\n        return frozenset(self._language)\n\n    @property\n    def consequences(self) -&gt; frozenset[Sequent]:\n        \"\"\"The base consequence relation |~_B (read-only view).\"\"\"\n        return frozenset(self._consequences)\n\n    # --- Mutation ---\n\n    def add_atom(self, s: str) -&gt; None:\n        \"\"\"Add an atomic sentence to the language L_B.\"\"\"\n        _validate_atomic(s, \"add_atom\")\n        self._language.add(s)\n        logger.debug(\"Added atom: %s\", s)\n\n    def add_consequence(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; None:\n        \"\"\"Add a base consequence Gamma |~_B Delta.\n\n        All sentences in *antecedent* and *consequent* must be atomic. They are\n        also implicitly added to the language.\n        \"\"\"\n        for s in antecedent | consequent:\n            _validate_atomic(s, \"add_consequence\")\n            self._language.add(s)\n        self._consequences.add((antecedent, consequent))\n        logger.debug(\"Added consequence: %s |~ %s\", set(antecedent), set(consequent))\n\n    # --- Axiom check ---\n\n    def is_axiom(self, gamma: frozenset[str], delta: frozenset[str]) -&gt; bool:\n        \"\"\"Check if Gamma =&gt; Delta is an axiom of NMMS_B.\n\n        Ax1 (Containment): Gamma \u2229 Delta \u2260 \u2205.\n        Ax2 (Base consequence): (Gamma, Delta) \u2208 |~_B exactly.\n\n        No Weakening: the base relation uses exact syntactic match.\n        \"\"\"\n        # Ax1: Containment\n        if gamma &amp; delta:\n            return True\n        # Ax2: Explicit base consequence (exact match)\n        if (gamma, delta) in self._consequences:\n            return True\n        return False\n\n    # --- Serialization ---\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Serialize to a JSON-compatible dict.\"\"\"\n        return {\n            \"language\": sorted(self._language),\n            \"consequences\": [\n                {\n                    \"antecedent\": sorted(gamma),\n                    \"consequent\": sorted(delta),\n                }\n                for gamma, delta in sorted(\n                    self._consequences, key=lambda s: (sorted(s[0]), sorted(s[1]))\n                )\n            ],\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; MaterialBase:\n        \"\"\"Deserialize from a dict (as produced by ``to_dict``).\"\"\"\n        language = set(data.get(\"language\", []))\n        consequences: set[Sequent] = set()\n        for entry in data.get(\"consequences\", []):\n            gamma = frozenset(entry[\"antecedent\"])\n            delta = frozenset(entry[\"consequent\"])\n            consequences.add((gamma, delta))\n        return cls(language=language, consequences=consequences)\n\n    def to_file(self, path: str | Path) -&gt; None:\n        \"\"\"Write the base to a JSON file.\"\"\"\n        with open(path, \"w\") as f:\n            json.dump(self.to_dict(), f, indent=2)\n        logger.debug(\"Saved base to %s\", path)\n\n    @classmethod\n    def from_file(cls, path: str | Path) -&gt; MaterialBase:\n        \"\"\"Load a base from a JSON file.\"\"\"\n        with open(path) as f:\n            data = json.load(f)\n        logger.debug(\"Loaded base from %s\", path)\n        return cls.from_dict(data)\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.language","title":"<code>language</code>  <code>property</code>","text":"<p>The atomic language L_B (read-only view).</p>"},{"location":"api/base/#pynmms.base.MaterialBase.consequences","title":"<code>consequences</code>  <code>property</code>","text":"<p>The base consequence relation |~_B (read-only view).</p>"},{"location":"api/base/#pynmms.base.MaterialBase.__init__","title":"<code>__init__(language=None, consequences=None)</code>","text":"Source code in <code>src/pynmms/base.py</code> <pre><code>def __init__(\n    self,\n    language: set[str] | frozenset[str] | None = None,\n    consequences: (\n        set[Sequent]\n        | set[tuple[frozenset[str], frozenset[str]]]\n        | None\n    ) = None,\n) -&gt; None:\n    self._language: set[str] = set(language) if language else set()\n    self._consequences: set[Sequent] = set()\n\n    # Validate all language atoms\n    for s in self._language:\n        _validate_atomic(s, \"Material base language\")\n\n    # Validate and store consequences\n    if consequences:\n        for gamma, delta in consequences:\n            for s in gamma | delta:\n                _validate_atomic(s, \"Material base consequence\")\n            self._consequences.add((gamma, delta))\n\n    logger.debug(\n        \"MaterialBase created: %d atoms, %d consequences\",\n        len(self._language),\n        len(self._consequences),\n    )\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.add_atom","title":"<code>add_atom(s)</code>","text":"<p>Add an atomic sentence to the language L_B.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>def add_atom(self, s: str) -&gt; None:\n    \"\"\"Add an atomic sentence to the language L_B.\"\"\"\n    _validate_atomic(s, \"add_atom\")\n    self._language.add(s)\n    logger.debug(\"Added atom: %s\", s)\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.add_consequence","title":"<code>add_consequence(antecedent, consequent)</code>","text":"<p>Add a base consequence Gamma |~_B Delta.</p> <p>All sentences in antecedent and consequent must be atomic. They are also implicitly added to the language.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>def add_consequence(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; None:\n    \"\"\"Add a base consequence Gamma |~_B Delta.\n\n    All sentences in *antecedent* and *consequent* must be atomic. They are\n    also implicitly added to the language.\n    \"\"\"\n    for s in antecedent | consequent:\n        _validate_atomic(s, \"add_consequence\")\n        self._language.add(s)\n    self._consequences.add((antecedent, consequent))\n    logger.debug(\"Added consequence: %s |~ %s\", set(antecedent), set(consequent))\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.is_axiom","title":"<code>is_axiom(gamma, delta)</code>","text":"<p>Check if Gamma =&gt; Delta is an axiom of NMMS_B.</p> <p>Ax1 (Containment): Gamma \u2229 Delta \u2260 \u2205. Ax2 (Base consequence): (Gamma, Delta) \u2208 |~_B exactly.</p> <p>No Weakening: the base relation uses exact syntactic match.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>def is_axiom(self, gamma: frozenset[str], delta: frozenset[str]) -&gt; bool:\n    \"\"\"Check if Gamma =&gt; Delta is an axiom of NMMS_B.\n\n    Ax1 (Containment): Gamma \u2229 Delta \u2260 \u2205.\n    Ax2 (Base consequence): (Gamma, Delta) \u2208 |~_B exactly.\n\n    No Weakening: the base relation uses exact syntactic match.\n    \"\"\"\n    # Ax1: Containment\n    if gamma &amp; delta:\n        return True\n    # Ax2: Explicit base consequence (exact match)\n    if (gamma, delta) in self._consequences:\n        return True\n    return False\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a JSON-compatible dict.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Serialize to a JSON-compatible dict.\"\"\"\n    return {\n        \"language\": sorted(self._language),\n        \"consequences\": [\n            {\n                \"antecedent\": sorted(gamma),\n                \"consequent\": sorted(delta),\n            }\n            for gamma, delta in sorted(\n                self._consequences, key=lambda s: (sorted(s[0]), sorted(s[1]))\n            )\n        ],\n    }\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Deserialize from a dict (as produced by <code>to_dict</code>).</p> Source code in <code>src/pynmms/base.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; MaterialBase:\n    \"\"\"Deserialize from a dict (as produced by ``to_dict``).\"\"\"\n    language = set(data.get(\"language\", []))\n    consequences: set[Sequent] = set()\n    for entry in data.get(\"consequences\", []):\n        gamma = frozenset(entry[\"antecedent\"])\n        delta = frozenset(entry[\"consequent\"])\n        consequences.add((gamma, delta))\n    return cls(language=language, consequences=consequences)\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.to_file","title":"<code>to_file(path)</code>","text":"<p>Write the base to a JSON file.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>def to_file(self, path: str | Path) -&gt; None:\n    \"\"\"Write the base to a JSON file.\"\"\"\n    with open(path, \"w\") as f:\n        json.dump(self.to_dict(), f, indent=2)\n    logger.debug(\"Saved base to %s\", path)\n</code></pre>"},{"location":"api/base/#pynmms.base.MaterialBase.from_file","title":"<code>from_file(path)</code>  <code>classmethod</code>","text":"<p>Load a base from a JSON file.</p> Source code in <code>src/pynmms/base.py</code> <pre><code>@classmethod\ndef from_file(cls, path: str | Path) -&gt; MaterialBase:\n    \"\"\"Load a base from a JSON file.\"\"\"\n    with open(path) as f:\n        data = json.load(f)\n    logger.debug(\"Loaded base from %s\", path)\n    return cls.from_dict(data)\n</code></pre>"},{"location":"api/reasoner/","title":"NMMSReasoner","text":""},{"location":"api/reasoner/#pynmms.reasoner.NMMSReasoner","title":"<code>pynmms.reasoner.NMMSReasoner</code>","text":"<p>Proof search for propositional NMMS sequent calculus.</p> <p>Performs backward (root-first) proof search with memoization and depth-limited search. A sequent Gamma =&gt; Delta is derivable iff all leaves of its proof tree are axioms of the material base.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>MaterialBase</code> <p>The material base providing axioms.</p> required <code>max_depth</code> <code>int</code> <p>Maximum proof depth (default 25).</p> <code>25</code> Source code in <code>src/pynmms/reasoner.py</code> <pre><code>class NMMSReasoner:\n    \"\"\"Proof search for propositional NMMS sequent calculus.\n\n    Performs backward (root-first) proof search with memoization and\n    depth-limited search. A sequent Gamma =&gt; Delta is derivable iff\n    all leaves of its proof tree are axioms of the material base.\n\n    Parameters:\n        base: The material base providing axioms.\n        max_depth: Maximum proof depth (default 25).\n    \"\"\"\n\n    def __init__(self, base: MaterialBase, *, max_depth: int = 25) -&gt; None:\n        self.base = base\n        self.max_depth = max_depth\n        self._trace: list[str] = []\n        self._cache: dict[tuple[frozenset[str], frozenset[str]], bool] = {}\n        self._depth_reached: int = 0\n        self._cache_hits: int = 0\n\n    def derives(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; ProofResult:\n        \"\"\"Check if ``antecedent =&gt; consequent`` is derivable in NMMS_B.\n\n        Returns a ``ProofResult`` with derivability, proof trace, and statistics.\n        \"\"\"\n        self._trace = []\n        self._cache = {}\n        self._depth_reached = 0\n        self._cache_hits = 0\n\n        logger.debug(\"Proof search: %s =&gt; %s\", _fmt(antecedent), _fmt(consequent))\n        result = self._prove(antecedent, consequent, depth=0)\n        logger.debug(\"Result: %s (depth %d, cache hits %d)\",\n                      result, self._depth_reached, self._cache_hits)\n\n        return ProofResult(\n            derivable=result,\n            trace=list(self._trace),\n            depth_reached=self._depth_reached,\n            cache_hits=self._cache_hits,\n        )\n\n    def query(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; bool:\n        \"\"\"Convenience method: return only the derivability boolean.\"\"\"\n        return self.derives(antecedent, consequent).derivable\n\n    # ------------------------------------------------------------------\n    # Internal proof search\n    # ------------------------------------------------------------------\n\n    def _prove(self, gamma: frozenset[str], delta: frozenset[str], depth: int) -&gt; bool:\n        \"\"\"Backward proof search with memoization.\"\"\"\n        indent = \"  \" * depth\n        self._depth_reached = max(self._depth_reached, depth)\n\n        if depth &gt; self.max_depth:\n            msg = f\"{indent}DEPTH LIMIT\"\n            self._trace.append(msg)\n            logger.debug(msg)\n            return False\n\n        # Memoization\n        key = (gamma, delta)\n        if key in self._cache:\n            self._cache_hits += 1\n            return self._cache[key]\n\n        # Check axiom\n        if self.base.is_axiom(gamma, delta):\n            msg = f\"{indent}AXIOM: {_fmt(gamma)} =&gt; {_fmt(delta)}\"\n            self._trace.append(msg)\n            logger.debug(msg)\n            self._cache[key] = True\n            return True\n\n        # Mark as False initially to detect cycles\n        self._cache[key] = False\n\n        result = self._try_left_rules(gamma, delta, depth) or self._try_right_rules(\n            gamma, delta, depth\n        )\n\n        self._cache[key] = result\n        if not result:\n            msg = f\"{indent}FAIL: {_fmt(gamma)} =&gt; {_fmt(delta)}\"\n            self._trace.append(msg)\n            logger.debug(msg)\n        return result\n\n    # ------------------------------------------------------------------\n    # LEFT RULES\n    # ------------------------------------------------------------------\n\n    def _try_left_rules(\n        self, gamma: frozenset[str], delta: frozenset[str], depth: int\n    ) -&gt; bool:\n        indent = \"  \" * depth\n\n        for s in sorted(gamma):  # sorted for determinism\n            parsed = parse_sentence(s)\n            rest = gamma - {s}\n\n            # [L~]: Gamma, ~A =&gt; Delta  &lt;-  Gamma =&gt; Delta, A\n            if parsed.type == NEG:\n                assert parsed.sub is not None\n                a = str(parsed.sub)\n                msg = f\"{indent}[L\\u00ac] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if self._prove(rest, delta | {a}, depth + 1):\n                    return True\n\n            # [L-&gt;]: Gamma, A-&gt;B =&gt; Delta  &lt;-  (1) Gamma =&gt; Delta, A\n            #                                   (2) Gamma, B =&gt; Delta\n            #                                   (3) Gamma, B =&gt; Delta, A\n            elif parsed.type == IMPL:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[L\\u2192] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if (\n                    self._prove(rest, delta | {a}, depth + 1)\n                    and self._prove(rest | {b}, delta, depth + 1)\n                    and self._prove(rest | {b}, delta | {a}, depth + 1)\n                ):\n                    return True\n\n            # [L&amp;]: Gamma, A &amp; B =&gt; Delta  &lt;-  Gamma, A, B =&gt; Delta\n            elif parsed.type == CONJ:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[L\\u2227] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if self._prove(rest | {a, b}, delta, depth + 1):\n                    return True\n\n            # [L|]: Gamma, A | B =&gt; Delta  &lt;-  (1) Gamma, A =&gt; Delta\n            #                                   (2) Gamma, B =&gt; Delta\n            #                                   (3) Gamma, A, B =&gt; Delta\n            elif parsed.type == DISJ:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[L\\u2228] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if (\n                    self._prove(rest | {a}, delta, depth + 1)\n                    and self._prove(rest | {b}, delta, depth + 1)\n                    and self._prove(rest | {a, b}, delta, depth + 1)\n                ):\n                    return True\n\n        return False\n\n    # ------------------------------------------------------------------\n    # RIGHT RULES\n    # ------------------------------------------------------------------\n\n    def _try_right_rules(\n        self, gamma: frozenset[str], delta: frozenset[str], depth: int\n    ) -&gt; bool:\n        indent = \"  \" * depth\n\n        for s in sorted(delta):\n            parsed = parse_sentence(s)\n            rest = delta - {s}\n\n            # [R~]: Gamma =&gt; Delta, ~A  &lt;-  Gamma, A =&gt; Delta\n            if parsed.type == NEG:\n                assert parsed.sub is not None\n                a = str(parsed.sub)\n                msg = f\"{indent}[R\\u00ac] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if self._prove(gamma | {a}, rest, depth + 1):\n                    return True\n\n            # [R-&gt;]: Gamma =&gt; Delta, A-&gt;B  &lt;-  Gamma, A =&gt; Delta, B\n            elif parsed.type == IMPL:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[R\\u2192] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if self._prove(gamma | {a}, rest | {b}, depth + 1):\n                    return True\n\n            # [R&amp;]: Gamma =&gt; Delta, A &amp; B  &lt;-  (1) Gamma =&gt; Delta, A\n            #                                   (2) Gamma =&gt; Delta, B\n            #                                   (3) Gamma =&gt; Delta, A, B\n            elif parsed.type == CONJ:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[R\\u2227] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if (\n                    self._prove(gamma, rest | {a}, depth + 1)\n                    and self._prove(gamma, rest | {b}, depth + 1)\n                    and self._prove(gamma, rest | {a, b}, depth + 1)\n                ):\n                    return True\n\n            # [R|]: Gamma =&gt; Delta, A | B  &lt;-  Gamma =&gt; Delta, A, B\n            elif parsed.type == DISJ:\n                assert parsed.left is not None and parsed.right is not None\n                a, b = str(parsed.left), str(parsed.right)\n                msg = f\"{indent}[R\\u2228] on {s}\"\n                self._trace.append(msg)\n                logger.debug(msg)\n                if self._prove(gamma, rest | {a, b}, depth + 1):\n                    return True\n\n        return False\n</code></pre>"},{"location":"api/reasoner/#pynmms.reasoner.NMMSReasoner.__init__","title":"<code>__init__(base, *, max_depth=25)</code>","text":"Source code in <code>src/pynmms/reasoner.py</code> <pre><code>def __init__(self, base: MaterialBase, *, max_depth: int = 25) -&gt; None:\n    self.base = base\n    self.max_depth = max_depth\n    self._trace: list[str] = []\n    self._cache: dict[tuple[frozenset[str], frozenset[str]], bool] = {}\n    self._depth_reached: int = 0\n    self._cache_hits: int = 0\n</code></pre>"},{"location":"api/reasoner/#pynmms.reasoner.NMMSReasoner.derives","title":"<code>derives(antecedent, consequent)</code>","text":"<p>Check if <code>antecedent =&gt; consequent</code> is derivable in NMMS_B.</p> <p>Returns a <code>ProofResult</code> with derivability, proof trace, and statistics.</p> Source code in <code>src/pynmms/reasoner.py</code> <pre><code>def derives(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; ProofResult:\n    \"\"\"Check if ``antecedent =&gt; consequent`` is derivable in NMMS_B.\n\n    Returns a ``ProofResult`` with derivability, proof trace, and statistics.\n    \"\"\"\n    self._trace = []\n    self._cache = {}\n    self._depth_reached = 0\n    self._cache_hits = 0\n\n    logger.debug(\"Proof search: %s =&gt; %s\", _fmt(antecedent), _fmt(consequent))\n    result = self._prove(antecedent, consequent, depth=0)\n    logger.debug(\"Result: %s (depth %d, cache hits %d)\",\n                  result, self._depth_reached, self._cache_hits)\n\n    return ProofResult(\n        derivable=result,\n        trace=list(self._trace),\n        depth_reached=self._depth_reached,\n        cache_hits=self._cache_hits,\n    )\n</code></pre>"},{"location":"api/reasoner/#pynmms.reasoner.NMMSReasoner.query","title":"<code>query(antecedent, consequent)</code>","text":"<p>Convenience method: return only the derivability boolean.</p> Source code in <code>src/pynmms/reasoner.py</code> <pre><code>def query(self, antecedent: frozenset[str], consequent: frozenset[str]) -&gt; bool:\n    \"\"\"Convenience method: return only the derivability boolean.\"\"\"\n    return self.derives(antecedent, consequent).derivable\n</code></pre>"},{"location":"api/reasoner/#pynmms.reasoner.ProofResult","title":"<code>pynmms.reasoner.ProofResult</code>  <code>dataclass</code>","text":"<p>Result of a proof search.</p> <p>Attributes:</p> Name Type Description <code>derivable</code> <code>bool</code> <p>Whether the sequent is derivable.</p> <code>trace</code> <code>list[str]</code> <p>Human-readable proof trace.</p> <code>depth_reached</code> <code>int</code> <p>Maximum proof depth reached.</p> <code>cache_hits</code> <code>int</code> <p>Number of memoization cache hits.</p> Source code in <code>src/pynmms/reasoner.py</code> <pre><code>@dataclass\nclass ProofResult:\n    \"\"\"Result of a proof search.\n\n    Attributes:\n        derivable: Whether the sequent is derivable.\n        trace: Human-readable proof trace.\n        depth_reached: Maximum proof depth reached.\n        cache_hits: Number of memoization cache hits.\n    \"\"\"\n\n    derivable: bool\n    trace: list[str] = field(default_factory=list)\n    depth_reached: int = 0\n    cache_hits: int = 0\n</code></pre>"},{"location":"api/rq-base/","title":"RQ Material Base","text":""},{"location":"api/rq-base/#pynmms.rq.base","title":"<code>pynmms.rq.base</code>","text":"<p>RQ Material Base \u2014 placeholder, implemented in Phase 2.</p>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase","title":"<code>RQMaterialBase</code>","text":"<p>               Bases: <code>MaterialBase</code></p> <p>A material base for NMMS with restricted quantifiers.</p> <p>Extends <code>MaterialBase</code> to accept concept/role assertions as atomic, track vocabulary (individuals, concepts, roles), and support lazy inference schemas.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>class RQMaterialBase(MaterialBase):\n    \"\"\"A material base for NMMS with restricted quantifiers.\n\n    Extends ``MaterialBase`` to accept concept/role assertions as atomic,\n    track vocabulary (individuals, concepts, roles), and support lazy\n    inference schemas.\n    \"\"\"\n\n    def __init__(\n        self,\n        language: set[str] | frozenset[str] | None = None,\n        consequences: (\n            set[Sequent] | set[tuple[frozenset[str], frozenset[str]]] | None\n        ) = None,\n    ) -&gt; None:\n        self._individuals: set[str] = set()\n        self._concepts: set[str] = set()\n        self._roles: set[str] = set()\n        self._inference_schemas: list[\n            tuple[str, str, str | None, frozenset[str]]\n        ] = []\n        # Temporarily bypass parent validation \u2014 we override _validate\n        self._rq_language: set[str] = set(language) if language else set()\n        self._rq_consequences: set[Sequent] = set()\n\n        # Validate RQ-atomic\n        for s in self._rq_language:\n            _validate_rq_atomic(s, \"RQ material base language\")\n            self._extract_vocab(s)\n\n        if consequences:\n            for gamma, delta in consequences:\n                for s in gamma | delta:\n                    _validate_rq_atomic(s, \"RQ material base consequence\")\n                    self._extract_vocab(s)\n                self._rq_consequences.add((gamma, delta))\n\n        # Initialize parent with empty sets \u2014 we manage storage ourselves\n        super().__init__()\n        self._language = self._rq_language\n        self._consequences = self._rq_consequences\n\n        logger.debug(\n            \"RQMaterialBase created: %d atoms, %d consequences, \"\n            \"%d individuals, %d concepts, %d roles\",\n            len(self._language),\n            len(self._consequences),\n            len(self._individuals),\n            len(self._concepts),\n            len(self._roles),\n        )\n\n    def _extract_vocab(self, s: str) -&gt; None:\n        \"\"\"Extract vocabulary (individuals, concepts, roles) from a sentence.\"\"\"\n        parsed = parse_rq_sentence(s)\n        if isinstance(parsed, RQSentence):\n            if parsed.type == ATOM_CONCEPT:\n                self._individuals.add(parsed.individual)  # type: ignore[arg-type]\n                self._concepts.add(parsed.concept)  # type: ignore[arg-type]\n            elif parsed.type == ATOM_ROLE:\n                self._individuals.add(parsed.arg1)  # type: ignore[arg-type]\n                self._individuals.add(parsed.arg2)  # type: ignore[arg-type]\n                self._roles.add(parsed.role)  # type: ignore[arg-type]\n\n    # --- Read-only properties ---\n\n    @property\n    def individuals(self) -&gt; frozenset[str]:\n        \"\"\"Known individuals (read-only).\"\"\"\n        return frozenset(self._individuals)\n\n    @property\n    def concepts(self) -&gt; frozenset[str]:\n        \"\"\"Known concepts (read-only).\"\"\"\n        return frozenset(self._concepts)\n\n    @property\n    def roles(self) -&gt; frozenset[str]:\n        \"\"\"Known roles (read-only).\"\"\"\n        return frozenset(self._roles)\n\n    # --- Mutation ---\n\n    def add_atom(self, s: str) -&gt; None:\n        \"\"\"Add an RQ-atomic sentence to the language.\"\"\"\n        _validate_rq_atomic(s, \"add_atom\")\n        self._language.add(s)\n        self._extract_vocab(s)\n        logger.debug(\"Added atom: %s\", s)\n\n    def add_consequence(\n        self, antecedent: frozenset[str], consequent: frozenset[str]\n    ) -&gt; None:\n        \"\"\"Add a base consequence. All sentences must be RQ-atomic.\"\"\"\n        for s in antecedent | consequent:\n            _validate_rq_atomic(s, \"add_consequence\")\n            self._language.add(s)\n            self._extract_vocab(s)\n        self._consequences.add((antecedent, consequent))\n        logger.debug(\"Added consequence: %s |~ %s\", set(antecedent), set(consequent))\n\n    def add_individual(self, role: str, subject: str, obj: str) -&gt; None:\n        \"\"\"Add a role assertion R(subject, obj) to the language.\"\"\"\n        role_assertion = make_role_assertion(role, subject, obj)\n        self._language.add(role_assertion)\n        self._extract_vocab(role_assertion)\n        logger.debug(\"Added individual: %s\", role_assertion)\n\n    # --- Schema registration ---\n\n    def register_concept_schema(\n        self, role: str, subject: str, concept: str\n    ) -&gt; None:\n        \"\"\"Register: for all role(subject, x), assert concept(x).\n\n        Stored lazily \u2014 not grounded over known individuals.\n        \"\"\"\n        self._inference_schemas.append((\n            role,\n            subject,\n            None,\n            frozenset({make_concept_assertion(concept, \"__OBJ__\")}),\n        ))\n        logger.debug(\n            \"Registered concept schema: %s(%s, x) |~ %s(x)\", role, subject, concept\n        )\n\n    def register_inference_schema(\n        self,\n        role: str,\n        subject: str,\n        premise_concept: str | None,\n        conclusion: set[str],\n    ) -&gt; None:\n        \"\"\"Register: for all role(subject, x) with premise_concept(x), conclude.\n\n        Conclusion may contain ``__OBJ__`` which is replaced with the\n        matched individual at query time.\n        \"\"\"\n        conclusion_fs = frozenset(conclusion)\n        self._inference_schemas.append(\n            (role, subject, premise_concept, conclusion_fs)\n        )\n        logger.debug(\n            \"Registered inference schema: %s(%s, x), %s(x) |~ %s\",\n            role,\n            subject,\n            premise_concept,\n            conclusion,\n        )\n\n    # --- Axiom check (overrides parent) ---\n\n    def is_axiom(self, gamma: frozenset[str], delta: frozenset[str]) -&gt; bool:\n        \"\"\"Check if Gamma =&gt; Delta is an axiom.\n\n        Ax1 (Containment): Gamma &amp; Delta != empty.\n        Ax2 (Base consequence): (Gamma, Delta) in |~_B exactly.\n        Ax3 (Schema consequence): matches a lazy schema.\n        \"\"\"\n        # Ax1: Containment\n        if gamma &amp; delta:\n            return True\n        # Ax2: Explicit base consequence (exact match)\n        if (gamma, delta) in self._consequences:\n            return True\n        # Ax3: Lazy schema evaluation\n        if self._inference_schemas and self._check_schemas(gamma, delta):\n            return True\n        return False\n\n    def _check_schemas(\n        self, gamma: frozenset[str], delta: frozenset[str]\n    ) -&gt; bool:\n        \"\"\"Check if any schema makes gamma |~ delta hold.\n\n        Exact match (no weakening) preserves nonmonotonicity.\n        \"\"\"\n        for schema_role, schema_subject, premise_concept, conclusion_template in (\n            self._inference_schemas\n        ):\n            for s in gamma:\n                parsed = parse_rq_sentence(s)\n                if (\n                    isinstance(parsed, RQSentence)\n                    and parsed.type == ATOM_ROLE\n                    and parsed.role == schema_role\n                    and parsed.arg1 == schema_subject\n                ):\n                    obj = parsed.arg2\n\n                    # Build expected gamma\n                    if premise_concept is not None:\n                        premise = make_concept_assertion(premise_concept, obj)  # type: ignore[arg-type]\n                        expected_gamma = frozenset({s, premise})\n                    else:\n                        expected_gamma = frozenset({s})\n\n                    # Build expected delta: substitute __OBJ__ with obj\n                    expected_delta = frozenset(\n                        c.replace(\"__OBJ__\", obj)  # type: ignore[arg-type]\n                        if \"__OBJ__\" in c\n                        else c\n                        for c in conclusion_template\n                    )\n\n                    # Exact match (no weakening)\n                    if gamma == expected_gamma and delta == expected_delta:\n                        return True\n\n        return False\n\n    # --- Serialization ---\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Serialize to a JSON-compatible dict, including schemas.\"\"\"\n        base_dict = super().to_dict()\n        base_dict[\"individuals\"] = sorted(self._individuals)\n        base_dict[\"concepts\"] = sorted(self._concepts)\n        base_dict[\"roles\"] = sorted(self._roles)\n        base_dict[\"schemas\"] = [\n            {\n                \"role\": role,\n                \"subject\": subject,\n                \"premise_concept\": premise_concept,\n                \"conclusion\": sorted(conclusion),\n            }\n            for role, subject, premise_concept, conclusion in self._inference_schemas\n        ]\n        return base_dict\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; RQMaterialBase:\n        \"\"\"Deserialize from a dict (as produced by ``to_dict``).\"\"\"\n        language = set(data.get(\"language\", []))\n        consequences: set[Sequent] = set()\n        for entry in data.get(\"consequences\", []):\n            gamma = frozenset(entry[\"antecedent\"])\n            delta = frozenset(entry[\"consequent\"])\n            consequences.add((gamma, delta))\n\n        base = cls(language=language, consequences=consequences)\n\n        # Restore schemas\n        for schema in data.get(\"schemas\", []):\n            base._inference_schemas.append((\n                schema[\"role\"],\n                schema[\"subject\"],\n                schema[\"premise_concept\"],\n                frozenset(schema[\"conclusion\"]),\n            ))\n\n        return base\n\n    def to_file(self, path: str | Path) -&gt; None:\n        \"\"\"Write the base to a JSON file.\"\"\"\n        with open(path, \"w\") as f:\n            json.dump(self.to_dict(), f, indent=2)\n        logger.debug(\"Saved RQ base to %s\", path)\n\n    @classmethod\n    def from_file(cls, path: str | Path) -&gt; RQMaterialBase:\n        \"\"\"Load a base from a JSON file.\"\"\"\n        with open(path) as f:\n            data = json.load(f)\n        logger.debug(\"Loaded RQ base from %s\", path)\n        return cls.from_dict(data)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.concepts","title":"<code>concepts</code>  <code>property</code>","text":"<p>Known concepts (read-only).</p>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.individuals","title":"<code>individuals</code>  <code>property</code>","text":"<p>Known individuals (read-only).</p>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.roles","title":"<code>roles</code>  <code>property</code>","text":"<p>Known roles (read-only).</p>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.add_atom","title":"<code>add_atom(s)</code>","text":"<p>Add an RQ-atomic sentence to the language.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_atom(self, s: str) -&gt; None:\n    \"\"\"Add an RQ-atomic sentence to the language.\"\"\"\n    _validate_rq_atomic(s, \"add_atom\")\n    self._language.add(s)\n    self._extract_vocab(s)\n    logger.debug(\"Added atom: %s\", s)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.add_consequence","title":"<code>add_consequence(antecedent, consequent)</code>","text":"<p>Add a base consequence. All sentences must be RQ-atomic.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_consequence(\n    self, antecedent: frozenset[str], consequent: frozenset[str]\n) -&gt; None:\n    \"\"\"Add a base consequence. All sentences must be RQ-atomic.\"\"\"\n    for s in antecedent | consequent:\n        _validate_rq_atomic(s, \"add_consequence\")\n        self._language.add(s)\n        self._extract_vocab(s)\n    self._consequences.add((antecedent, consequent))\n    logger.debug(\"Added consequence: %s |~ %s\", set(antecedent), set(consequent))\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.add_individual","title":"<code>add_individual(role, subject, obj)</code>","text":"<p>Add a role assertion R(subject, obj) to the language.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_individual(self, role: str, subject: str, obj: str) -&gt; None:\n    \"\"\"Add a role assertion R(subject, obj) to the language.\"\"\"\n    role_assertion = make_role_assertion(role, subject, obj)\n    self._language.add(role_assertion)\n    self._extract_vocab(role_assertion)\n    logger.debug(\"Added individual: %s\", role_assertion)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Deserialize from a dict (as produced by <code>to_dict</code>).</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; RQMaterialBase:\n    \"\"\"Deserialize from a dict (as produced by ``to_dict``).\"\"\"\n    language = set(data.get(\"language\", []))\n    consequences: set[Sequent] = set()\n    for entry in data.get(\"consequences\", []):\n        gamma = frozenset(entry[\"antecedent\"])\n        delta = frozenset(entry[\"consequent\"])\n        consequences.add((gamma, delta))\n\n    base = cls(language=language, consequences=consequences)\n\n    # Restore schemas\n    for schema in data.get(\"schemas\", []):\n        base._inference_schemas.append((\n            schema[\"role\"],\n            schema[\"subject\"],\n            schema[\"premise_concept\"],\n            frozenset(schema[\"conclusion\"]),\n        ))\n\n    return base\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.from_file","title":"<code>from_file(path)</code>  <code>classmethod</code>","text":"<p>Load a base from a JSON file.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>@classmethod\ndef from_file(cls, path: str | Path) -&gt; RQMaterialBase:\n    \"\"\"Load a base from a JSON file.\"\"\"\n    with open(path) as f:\n        data = json.load(f)\n    logger.debug(\"Loaded RQ base from %s\", path)\n    return cls.from_dict(data)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.is_axiom","title":"<code>is_axiom(gamma, delta)</code>","text":"<p>Check if Gamma =&gt; Delta is an axiom.</p> <p>Ax1 (Containment): Gamma &amp; Delta != empty. Ax2 (Base consequence): (Gamma, Delta) in |~_B exactly. Ax3 (Schema consequence): matches a lazy schema.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def is_axiom(self, gamma: frozenset[str], delta: frozenset[str]) -&gt; bool:\n    \"\"\"Check if Gamma =&gt; Delta is an axiom.\n\n    Ax1 (Containment): Gamma &amp; Delta != empty.\n    Ax2 (Base consequence): (Gamma, Delta) in |~_B exactly.\n    Ax3 (Schema consequence): matches a lazy schema.\n    \"\"\"\n    # Ax1: Containment\n    if gamma &amp; delta:\n        return True\n    # Ax2: Explicit base consequence (exact match)\n    if (gamma, delta) in self._consequences:\n        return True\n    # Ax3: Lazy schema evaluation\n    if self._inference_schemas and self._check_schemas(gamma, delta):\n        return True\n    return False\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.register_concept_schema","title":"<code>register_concept_schema(role, subject, concept)</code>","text":"<p>Register: for all role(subject, x), assert concept(x).</p> <p>Stored lazily \u2014 not grounded over known individuals.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def register_concept_schema(\n    self, role: str, subject: str, concept: str\n) -&gt; None:\n    \"\"\"Register: for all role(subject, x), assert concept(x).\n\n    Stored lazily \u2014 not grounded over known individuals.\n    \"\"\"\n    self._inference_schemas.append((\n        role,\n        subject,\n        None,\n        frozenset({make_concept_assertion(concept, \"__OBJ__\")}),\n    ))\n    logger.debug(\n        \"Registered concept schema: %s(%s, x) |~ %s(x)\", role, subject, concept\n    )\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.register_inference_schema","title":"<code>register_inference_schema(role, subject, premise_concept, conclusion)</code>","text":"<p>Register: for all role(subject, x) with premise_concept(x), conclude.</p> <p>Conclusion may contain <code>__OBJ__</code> which is replaced with the matched individual at query time.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def register_inference_schema(\n    self,\n    role: str,\n    subject: str,\n    premise_concept: str | None,\n    conclusion: set[str],\n) -&gt; None:\n    \"\"\"Register: for all role(subject, x) with premise_concept(x), conclude.\n\n    Conclusion may contain ``__OBJ__`` which is replaced with the\n    matched individual at query time.\n    \"\"\"\n    conclusion_fs = frozenset(conclusion)\n    self._inference_schemas.append(\n        (role, subject, premise_concept, conclusion_fs)\n    )\n    logger.debug(\n        \"Registered inference schema: %s(%s, x), %s(x) |~ %s\",\n        role,\n        subject,\n        premise_concept,\n        conclusion,\n    )\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a JSON-compatible dict, including schemas.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Serialize to a JSON-compatible dict, including schemas.\"\"\"\n    base_dict = super().to_dict()\n    base_dict[\"individuals\"] = sorted(self._individuals)\n    base_dict[\"concepts\"] = sorted(self._concepts)\n    base_dict[\"roles\"] = sorted(self._roles)\n    base_dict[\"schemas\"] = [\n        {\n            \"role\": role,\n            \"subject\": subject,\n            \"premise_concept\": premise_concept,\n            \"conclusion\": sorted(conclusion),\n        }\n        for role, subject, premise_concept, conclusion in self._inference_schemas\n    ]\n    return base_dict\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.RQMaterialBase.to_file","title":"<code>to_file(path)</code>","text":"<p>Write the base to a JSON file.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def to_file(self, path: str | Path) -&gt; None:\n    \"\"\"Write the base to a JSON file.\"\"\"\n    with open(path, \"w\") as f:\n        json.dump(self.to_dict(), f, indent=2)\n    logger.debug(\"Saved RQ base to %s\", path)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore","title":"<code>CommitmentStore</code>","text":"<p>Manages quantified commitments and compiles them to an RQMaterialBase.</p> <p>Higher-level API for managing assertions and schemas, bridging natural language commitments to the atomic material base.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>class CommitmentStore:\n    \"\"\"Manages quantified commitments and compiles them to an RQMaterialBase.\n\n    Higher-level API for managing assertions and schemas, bridging natural\n    language commitments to the atomic material base.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.assertions: set[str] = set()\n        self.schemas: list[InferenceSchema] = []\n        self._ground_rules: set[Sequent] = set()\n        self._base: RQMaterialBase | None = None\n\n    def add_assertion(self, s: str) -&gt; None:\n        \"\"\"Add an atomic assertion.\"\"\"\n        _validate_rq_atomic(s, \"CommitmentStore.add_assertion\")\n        self.assertions.add(s)\n        self._base = None\n\n    def add_role(self, role: str, subject: str, obj: str) -&gt; None:\n        \"\"\"Add a role assertion R(subject, obj).\"\"\"\n        self.add_assertion(make_role_assertion(role, subject, obj))\n\n    def add_concept(self, concept: str, individual: str) -&gt; None:\n        \"\"\"Add a concept assertion C(individual).\"\"\"\n        self.add_assertion(make_concept_assertion(concept, individual))\n\n    def commit_universal(\n        self,\n        source: str,\n        role: str,\n        subject_var: str,\n        trigger_concept: str,\n        conclusion_concept: str,\n    ) -&gt; None:\n        \"\"\"Record a universal quantified commitment.\"\"\"\n        schema = InferenceSchema(\n            source=source,\n            role=role,\n            subject_var=subject_var,\n            trigger_concept=trigger_concept,\n            conclusion_concept=conclusion_concept,\n        )\n        self.schemas.append(schema)\n        self._base = None\n\n    def commit_defeasible_rule(\n        self,\n        source: str,\n        antecedent: frozenset[str],\n        consequent: frozenset[str],\n    ) -&gt; None:\n        \"\"\"Record a ground defeasible material inference.\"\"\"\n        for s in antecedent | consequent:\n            _validate_rq_atomic(s, f\"commit_defeasible_rule ({source})\")\n            self.assertions.add(s)\n        self._ground_rules.add((antecedent, consequent))\n        self._base = None\n\n    def retract_schema(self, source: str) -&gt; None:\n        \"\"\"Retract all schemas with the given source.\"\"\"\n        self.schemas = [s for s in self.schemas if s.source != source]\n        self._base = None\n\n    def compile(self) -&gt; RQMaterialBase:\n        \"\"\"Compile current commitments into an RQMaterialBase.\n\n        Schemas are registered lazily \u2014 no eager grounding.\n        \"\"\"\n        if self._base is not None:\n            return self._base\n\n        language = set(self.assertions)\n        consequences: set[Sequent] = set(self._ground_rules)\n\n        self._base = RQMaterialBase(\n            language=language,\n            consequences=consequences,\n        )\n\n        # Register schemas lazily\n        for schema in self.schemas:\n            if schema.trigger_concept:\n                conclusion = make_concept_assertion(\n                    schema.conclusion_concept, \"__OBJ__\"\n                )\n                self._base.register_inference_schema(\n                    schema.role,\n                    schema.subject_var,\n                    schema.trigger_concept,\n                    {conclusion},\n                )\n            else:\n                self._base.register_concept_schema(\n                    schema.role,\n                    schema.subject_var,\n                    schema.conclusion_concept,\n                )\n\n        return self._base\n\n    def describe(self) -&gt; str:\n        \"\"\"Human-readable description of current commitments.\"\"\"\n        lines = [\"Commitment Store:\"]\n        lines.append(f\"  Assertions: {len(self.assertions)}\")\n        for s in sorted(self.assertions):\n            lines.append(f\"    {s}\")\n        lines.append(f\"  Schemas: {len(self.schemas)}\")\n        for schema in self.schemas:\n            lines.append(f\"    [{schema.source}]\")\n            lines.append(\n                f\"      {schema.role}({schema.subject_var}, x)\"\n                f\", {schema.trigger_concept}(x)\"\n                if schema.trigger_concept\n                else f\"      {schema.role}({schema.subject_var}, x)\"\n                f\" |~ {schema.conclusion_concept}(x)\"\n            )\n        if self._ground_rules:\n            lines.append(f\"  Ground rules: {len(self._ground_rules)}\")\n            for ant, con in self._ground_rules:\n                lines.append(f\"    {set(ant)} |~ {set(con)}\")\n        return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.add_assertion","title":"<code>add_assertion(s)</code>","text":"<p>Add an atomic assertion.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_assertion(self, s: str) -&gt; None:\n    \"\"\"Add an atomic assertion.\"\"\"\n    _validate_rq_atomic(s, \"CommitmentStore.add_assertion\")\n    self.assertions.add(s)\n    self._base = None\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.add_concept","title":"<code>add_concept(concept, individual)</code>","text":"<p>Add a concept assertion C(individual).</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_concept(self, concept: str, individual: str) -&gt; None:\n    \"\"\"Add a concept assertion C(individual).\"\"\"\n    self.add_assertion(make_concept_assertion(concept, individual))\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.add_role","title":"<code>add_role(role, subject, obj)</code>","text":"<p>Add a role assertion R(subject, obj).</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def add_role(self, role: str, subject: str, obj: str) -&gt; None:\n    \"\"\"Add a role assertion R(subject, obj).\"\"\"\n    self.add_assertion(make_role_assertion(role, subject, obj))\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.commit_defeasible_rule","title":"<code>commit_defeasible_rule(source, antecedent, consequent)</code>","text":"<p>Record a ground defeasible material inference.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def commit_defeasible_rule(\n    self,\n    source: str,\n    antecedent: frozenset[str],\n    consequent: frozenset[str],\n) -&gt; None:\n    \"\"\"Record a ground defeasible material inference.\"\"\"\n    for s in antecedent | consequent:\n        _validate_rq_atomic(s, f\"commit_defeasible_rule ({source})\")\n        self.assertions.add(s)\n    self._ground_rules.add((antecedent, consequent))\n    self._base = None\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.commit_universal","title":"<code>commit_universal(source, role, subject_var, trigger_concept, conclusion_concept)</code>","text":"<p>Record a universal quantified commitment.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def commit_universal(\n    self,\n    source: str,\n    role: str,\n    subject_var: str,\n    trigger_concept: str,\n    conclusion_concept: str,\n) -&gt; None:\n    \"\"\"Record a universal quantified commitment.\"\"\"\n    schema = InferenceSchema(\n        source=source,\n        role=role,\n        subject_var=subject_var,\n        trigger_concept=trigger_concept,\n        conclusion_concept=conclusion_concept,\n    )\n    self.schemas.append(schema)\n    self._base = None\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.compile","title":"<code>compile()</code>","text":"<p>Compile current commitments into an RQMaterialBase.</p> <p>Schemas are registered lazily \u2014 no eager grounding.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def compile(self) -&gt; RQMaterialBase:\n    \"\"\"Compile current commitments into an RQMaterialBase.\n\n    Schemas are registered lazily \u2014 no eager grounding.\n    \"\"\"\n    if self._base is not None:\n        return self._base\n\n    language = set(self.assertions)\n    consequences: set[Sequent] = set(self._ground_rules)\n\n    self._base = RQMaterialBase(\n        language=language,\n        consequences=consequences,\n    )\n\n    # Register schemas lazily\n    for schema in self.schemas:\n        if schema.trigger_concept:\n            conclusion = make_concept_assertion(\n                schema.conclusion_concept, \"__OBJ__\"\n            )\n            self._base.register_inference_schema(\n                schema.role,\n                schema.subject_var,\n                schema.trigger_concept,\n                {conclusion},\n            )\n        else:\n            self._base.register_concept_schema(\n                schema.role,\n                schema.subject_var,\n                schema.conclusion_concept,\n            )\n\n    return self._base\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.describe","title":"<code>describe()</code>","text":"<p>Human-readable description of current commitments.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def describe(self) -&gt; str:\n    \"\"\"Human-readable description of current commitments.\"\"\"\n    lines = [\"Commitment Store:\"]\n    lines.append(f\"  Assertions: {len(self.assertions)}\")\n    for s in sorted(self.assertions):\n        lines.append(f\"    {s}\")\n    lines.append(f\"  Schemas: {len(self.schemas)}\")\n    for schema in self.schemas:\n        lines.append(f\"    [{schema.source}]\")\n        lines.append(\n            f\"      {schema.role}({schema.subject_var}, x)\"\n            f\", {schema.trigger_concept}(x)\"\n            if schema.trigger_concept\n            else f\"      {schema.role}({schema.subject_var}, x)\"\n            f\" |~ {schema.conclusion_concept}(x)\"\n        )\n    if self._ground_rules:\n        lines.append(f\"  Ground rules: {len(self._ground_rules)}\")\n        for ant, con in self._ground_rules:\n            lines.append(f\"    {set(ant)} |~ {set(con)}\")\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.CommitmentStore.retract_schema","title":"<code>retract_schema(source)</code>","text":"<p>Retract all schemas with the given source.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>def retract_schema(self, source: str) -&gt; None:\n    \"\"\"Retract all schemas with the given source.\"\"\"\n    self.schemas = [s for s in self.schemas if s.source != source]\n    self._base = None\n</code></pre>"},{"location":"api/rq-base/#pynmms.rq.base.InferenceSchema","title":"<code>InferenceSchema</code>  <code>dataclass</code>","text":"<p>A defeasible material inference schema from a quantified commitment.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>str</code> <p>The formal commitment that generated this schema.</p> <code>role</code> <code>str</code> <p>The role that scopes the quantification.</p> <code>subject_var</code> <code>str</code> <p>The variable being quantified over.</p> <code>trigger_concept</code> <code>str | None</code> <p>Concept in the restriction (or None).</p> <code>conclusion_concept</code> <code>str</code> <p>Concept concluded.</p> Source code in <code>src/pynmms/rq/base.py</code> <pre><code>@dataclass\nclass InferenceSchema:\n    \"\"\"A defeasible material inference schema from a quantified commitment.\n\n    Attributes:\n        source: The formal commitment that generated this schema.\n        role: The role that scopes the quantification.\n        subject_var: The variable being quantified over.\n        trigger_concept: Concept in the restriction (or None).\n        conclusion_concept: Concept concluded.\n    \"\"\"\n\n    source: str\n    role: str\n    subject_var: str\n    trigger_concept: str | None\n    conclusion_concept: str\n</code></pre>"},{"location":"api/rq-reasoner/","title":"RQ Reasoner","text":""},{"location":"api/rq-reasoner/#pynmms.rq.reasoner","title":"<code>pynmms.rq.reasoner</code>","text":"<p>NMMS proof search with restricted quantifier rules.</p> <p>Extends the propositional <code>NMMSReasoner</code> with four quantifier rules:</p> Left rules <p>[L-ALL-R.C]  Gamma, ALL R.C(a) =&gt; Delta              &lt;- Gamma, {C(b) | R(a,b) in Gamma} =&gt; Delta [L-SOME-R.C] Gamma, SOME R.C(a) =&gt; Delta              &lt;- for all nonempty subsets S of triggered {C(b)}:                 Gamma, S =&gt; Delta</p> Right rules <p>[R-SOME-R.C] Gamma =&gt; Delta, SOME R.C(a)              &lt;- (i) known witnesses: Gamma =&gt; Delta, C(b) for R(a,b) in Gamma                 (ii) fresh canonical witness with blocking [R-ALL-R.C]  Gamma =&gt; Delta, ALL R.C(a)              &lt;- Gamma, R(a,b) =&gt; Delta, C(b)  for fresh eigenvariable b</p>"},{"location":"api/rq-reasoner/#pynmms.rq.reasoner.NMMSRQReasoner","title":"<code>NMMSRQReasoner</code>","text":"<p>               Bases: <code>NMMSReasoner</code></p> <p>Proof search for NMMS with restricted quantifiers.</p> <p>Extends <code>NMMSReasoner</code> by overriding <code>_try_left_rules</code> and <code>_try_right_rules</code> to handle both propositional and RQ sentence types in a single pass using <code>parse_rq_sentence</code>.</p> Source code in <code>src/pynmms/rq/reasoner.py</code> <pre><code>class NMMSRQReasoner(NMMSReasoner):\n    \"\"\"Proof search for NMMS with restricted quantifiers.\n\n    Extends ``NMMSReasoner`` by overriding ``_try_left_rules`` and\n    ``_try_right_rules`` to handle both propositional and RQ sentence\n    types in a single pass using ``parse_rq_sentence``.\n    \"\"\"\n\n    def __init__(self, base: MaterialBase, *, max_depth: int = 25) -&gt; None:\n        super().__init__(base, max_depth=max_depth)\n\n    # ------------------------------------------------------------------\n    # LEFT RULES (propositional + quantifier)\n    # ------------------------------------------------------------------\n\n    def _try_left_rules(\n        self, gamma: frozenset[str], delta: frozenset[str], depth: int\n    ) -&gt; bool:\n        indent = \"  \" * depth\n\n        for s in sorted(gamma):  # sorted for determinism\n            parsed = parse_rq_sentence(s)\n            rest = gamma - {s}\n\n            if isinstance(parsed, Sentence):\n                # Propositional rules\n                # [L~]: Gamma, ~A =&gt; Delta  &lt;-  Gamma =&gt; Delta, A\n                if parsed.type == NEG:\n                    assert parsed.sub is not None\n                    a = str(parsed.sub)\n                    msg = f\"{indent}[L\\u00ac] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if self._prove(rest, delta | {a}, depth + 1):\n                        return True\n\n                # [L-&gt;]: 3 subgoals\n                elif parsed.type == IMPL:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[L\\u2192] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if (\n                        self._prove(rest, delta | {a}, depth + 1)\n                        and self._prove(rest | {b}, delta, depth + 1)\n                        and self._prove(rest | {b}, delta | {a}, depth + 1)\n                    ):\n                        return True\n\n                # [L&amp;]: Gamma, A &amp; B =&gt; Delta  &lt;-  Gamma, A, B =&gt; Delta\n                elif parsed.type == CONJ:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[L\\u2227] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if self._prove(rest | {a, b}, delta, depth + 1):\n                        return True\n\n                # [L|]: 3 subgoals\n                elif parsed.type == DISJ:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[L\\u2228] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if (\n                        self._prove(rest | {a}, delta, depth + 1)\n                        and self._prove(rest | {b}, delta, depth + 1)\n                        and self._prove(rest | {a, b}, delta, depth + 1)\n                    ):\n                        return True\n\n            elif isinstance(parsed, RQSentence):\n                # [L-ALL-R.C]: Gamma, ALL R.C(a) =&gt; Delta\n                #   Adjunction (OQ-1, option A): one subgoal adding all\n                #   triggered instances.\n                if parsed.type == ALL_RESTRICT:\n                    role_name = parsed.role\n                    concept = parsed.concept\n                    subject = parsed.individual\n                    assert role_name is not None\n                    assert concept is not None\n                    assert subject is not None\n                    triggers = find_role_triggers(rest, role_name, subject)\n\n                    if triggers:\n                        instances = frozenset(\n                            make_concept_assertion(concept, b) for b in triggers\n                        )\n                        msg = (\n                            f\"{indent}[L\\u2200R.C] on {s}, \"\n                            f\"triggers: {sorted(triggers)} \"\n                            f\"\\u2192 adding {sorted(instances)}\"\n                        )\n                        self._trace.append(msg)\n                        logger.debug(msg)\n                        if self._prove(rest | instances, delta, depth + 1):\n                            return True\n\n                # [L-SOME-R.C]: Gamma, SOME R.C(a) =&gt; Delta\n                #   Ketonen pattern: all 2^k - 1 nonempty subsets of\n                #   triggered instances must independently prove the\n                #   conclusion.\n                elif parsed.type == SOME_RESTRICT:\n                    role_name = parsed.role\n                    concept = parsed.concept\n                    subject = parsed.individual\n                    assert role_name is not None\n                    assert concept is not None\n                    assert subject is not None\n                    triggers = find_role_triggers(rest, role_name, subject)\n\n                    if triggers:\n                        instance_list = [\n                            make_concept_assertion(concept, b) for b in triggers\n                        ]\n                        msg = (\n                            f\"{indent}[L\\u2203R.C] on {s}, \"\n                            f\"triggers: {sorted(triggers)} \"\n                            f\"\\u2192 Ketonen over {len(instance_list)} instances \"\n                            f\"({2**len(instance_list) - 1} subsets)\"\n                        )\n                        self._trace.append(msg)\n                        logger.debug(msg)\n\n                        all_ok = True\n                        for r in range(1, len(instance_list) + 1):\n                            for subset in combinations(instance_list, r):\n                                if not self._prove(\n                                    rest | frozenset(subset), delta, depth + 1\n                                ):\n                                    all_ok = False\n                                    break\n                            if not all_ok:\n                                break\n\n                        if all_ok:\n                            return True\n\n        return False\n\n    # ------------------------------------------------------------------\n    # RIGHT RULES (propositional + quantifier)\n    # ------------------------------------------------------------------\n\n    def _try_right_rules(\n        self, gamma: frozenset[str], delta: frozenset[str], depth: int\n    ) -&gt; bool:\n        global _BLOCKING_WARNING_ISSUED\n        indent = \"  \" * depth\n\n        for s in sorted(delta):\n            parsed = parse_rq_sentence(s)\n            rest = delta - {s}\n\n            if isinstance(parsed, Sentence):\n                # Propositional rules\n                # [R~]: Gamma =&gt; Delta, ~A  &lt;-  Gamma, A =&gt; Delta\n                if parsed.type == NEG:\n                    assert parsed.sub is not None\n                    a = str(parsed.sub)\n                    msg = f\"{indent}[R\\u00ac] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if self._prove(gamma | {a}, rest, depth + 1):\n                        return True\n\n                # [R-&gt;]: Gamma =&gt; Delta, A-&gt;B  &lt;-  Gamma, A =&gt; Delta, B\n                elif parsed.type == IMPL:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[R\\u2192] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if self._prove(gamma | {a}, rest | {b}, depth + 1):\n                        return True\n\n                # [R&amp;]: 3 subgoals\n                elif parsed.type == CONJ:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[R\\u2227] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if (\n                        self._prove(gamma, rest | {a}, depth + 1)\n                        and self._prove(gamma, rest | {b}, depth + 1)\n                        and self._prove(gamma, rest | {a, b}, depth + 1)\n                    ):\n                        return True\n\n                # [R|]: Gamma =&gt; Delta, A | B  &lt;-  Gamma =&gt; Delta, A, B\n                elif parsed.type == DISJ:\n                    assert parsed.left is not None and parsed.right is not None\n                    a, b = str(parsed.left), str(parsed.right)\n                    msg = f\"{indent}[R\\u2228] on {s}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n                    if self._prove(gamma, rest | {a, b}, depth + 1):\n                        return True\n\n            elif isinstance(parsed, RQSentence):\n                # [R-SOME-R.C]: Gamma =&gt; Delta, SOME R.C(a)\n                #   (i) known witnesses, (ii) fresh canonical with blocking\n                if parsed.type == SOME_RESTRICT:\n                    role_name = parsed.role\n                    concept = parsed.concept\n                    subject = parsed.individual\n                    assert role_name is not None\n                    assert concept is not None\n                    assert subject is not None\n\n                    used = collect_individuals(gamma | delta)\n                    known_triggers = find_role_triggers(gamma, role_name, subject)\n\n                    msg = (\n                        f\"{indent}[R\\u2203R.C] on {s}, \"\n                        f\"known witnesses: {sorted(known_triggers)}\"\n                    )\n                    self._trace.append(msg)\n                    logger.debug(msg)\n\n                    # Strategy (i): known witnesses\n                    for b in known_triggers:\n                        c_b = make_concept_assertion(concept, b)\n                        if self._prove(gamma, rest | {c_b}, depth + 1):\n                            return True\n\n                    # Strategy (ii): fresh canonical witness\n                    canonical_fresh = f\"_w_{role_name}_{concept}_{subject}\"\n\n                    if canonical_fresh not in used:\n                        blocker = find_blocking_individual(\n                            canonical_fresh, gamma, delta, used\n                        )\n                        if blocker is not None:\n                            if not _BLOCKING_WARNING_ISSUED:\n                                warnings.warn(\n                                    \"Concept-label blocking is an experimental \"\n                                    \"conjecture. See RQ documentation for details.\",\n                                    stacklevel=2,\n                                )\n                                _BLOCKING_WARNING_ISSUED = True\n                            block_msg = (\n                                f\"{indent}  fresh {canonical_fresh} \"\n                                f\"blocked by {blocker}\"\n                            )\n                            self._trace.append(block_msg)\n                            logger.warning(\n                                \"Blocking fired: %s blocked by %s\",\n                                canonical_fresh,\n                                blocker,\n                            )\n                        else:\n                            c_b = make_concept_assertion(concept, canonical_fresh)\n                            r_ab = make_role_assertion(\n                                role_name, subject, canonical_fresh\n                            )\n                            fresh_msg = (\n                                f\"{indent}  trying fresh witness {canonical_fresh}\"\n                            )\n                            self._trace.append(fresh_msg)\n                            logger.debug(fresh_msg)\n                            if self._prove(\n                                gamma | {r_ab}, rest | {c_b}, depth + 1\n                            ):\n                                return True\n\n                # [R-ALL-R.C]: Gamma =&gt; Delta, ALL R.C(a)\n                #   Fresh eigenvariable, prove Gamma, R(a,b) =&gt; Delta, C(b)\n                elif parsed.type == ALL_RESTRICT:\n                    role_name = parsed.role\n                    concept = parsed.concept\n                    subject = parsed.individual\n                    assert role_name is not None\n                    assert concept is not None\n                    assert subject is not None\n\n                    canonical_eigen = f\"_e_{role_name}_{concept}_{subject}\"\n                    used = collect_individuals(gamma | delta)\n\n                    if canonical_eigen in used:\n                        b = fresh_individual(\n                            used, prefix=canonical_eigen + \"_\"\n                        )\n                    else:\n                        b = canonical_eigen\n\n                    r_ab = make_role_assertion(role_name, subject, b)\n                    c_b = make_concept_assertion(concept, b)\n\n                    msg = f\"{indent}[R\\u2200R.C] on {s}, eigen {b}\"\n                    self._trace.append(msg)\n                    logger.debug(msg)\n\n                    if self._prove(gamma | {r_ab}, rest | {c_b}, depth + 1):\n                        return True\n\n        return False\n</code></pre>"},{"location":"api/rq-syntax/","title":"RQ Syntax","text":""},{"location":"api/rq-syntax/#pynmms.rq.syntax","title":"<code>pynmms.rq.syntax</code>","text":"<p>Sentence parsing for NMMS with restricted quantifiers.</p> <p>Extends the propositional parser with ALC-style restricted quantifiers (<code>ALL R.C(a)</code>, <code>SOME R.C(a)</code>), concept assertions (<code>C(a)</code>), and role assertions (<code>R(a,b)</code>).</p> <p>Grammar additions (beyond propositional)::</p> <pre><code>quantified    ::= ('ALL' | 'SOME') ROLE '.' CONCEPT '(' INDIVIDUAL ')'\nconcept_atom  ::= CONCEPT '(' INDIVIDUAL ')'\nrole_atom     ::= ROLE '(' INDIVIDUAL ',' INDIVIDUAL ')'\n</code></pre> <p>The parser tries RQ-specific patterns first (quantifiers, role assertions, concept assertions), then falls through to propositional binary connectives, then bare atoms.</p>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.RQSentence","title":"<code>RQSentence</code>  <code>dataclass</code>","text":"<p>Immutable AST node for a restricted-quantifier sentence.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>One of ATOM_CONCEPT, ATOM_ROLE, ALL_RESTRICT, SOME_RESTRICT.</p> <code>concept</code> <code>str | None</code> <p>Concept name (for concept assertions and quantifiers).</p> <code>individual</code> <code>str | None</code> <p>Individual name (for concept assertions and quantifiers).</p> <code>role</code> <code>str | None</code> <p>Role name (for role assertions and quantifiers).</p> <code>arg1</code> <code>str | None</code> <p>First argument of role assertion.</p> <code>arg2</code> <code>str | None</code> <p>Second argument of role assertion.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass RQSentence:\n    \"\"\"Immutable AST node for a restricted-quantifier sentence.\n\n    Attributes:\n        type: One of ATOM_CONCEPT, ATOM_ROLE, ALL_RESTRICT, SOME_RESTRICT.\n        concept: Concept name (for concept assertions and quantifiers).\n        individual: Individual name (for concept assertions and quantifiers).\n        role: Role name (for role assertions and quantifiers).\n        arg1: First argument of role assertion.\n        arg2: Second argument of role assertion.\n    \"\"\"\n\n    type: str\n    concept: str | None = None\n    individual: str | None = None\n    role: str | None = None\n    arg1: str | None = None\n    arg2: str | None = None\n\n    def __str__(self) -&gt; str:\n        if self.type == ATOM_CONCEPT:\n            return f\"{self.concept}({self.individual})\"\n        if self.type == ATOM_ROLE:\n            return f\"{self.role}({self.arg1},{self.arg2})\"\n        if self.type == ALL_RESTRICT:\n            return f\"ALL {self.role}.{self.concept}({self.individual})\"\n        if self.type == SOME_RESTRICT:\n            return f\"SOME {self.role}.{self.concept}({self.individual})\"\n        return f\"RQSentence({self.type})\"  # pragma: no cover\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.parse_rq_sentence","title":"<code>parse_rq_sentence(s)</code>","text":"<p>Parse a string into a propositional Sentence or RQSentence AST.</p> <p>Tries RQ patterns first (quantifiers, role assertions, concept assertions), then falls through to propositional binary connectives (recursing with <code>parse_rq_sentence</code>), then bare atoms via the propositional parser.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def parse_rq_sentence(s: str) -&gt; Sentence | RQSentence:\n    \"\"\"Parse a string into a propositional Sentence or RQSentence AST.\n\n    Tries RQ patterns first (quantifiers, role assertions, concept assertions),\n    then falls through to propositional binary connectives (recursing with\n    ``parse_rq_sentence``), then bare atoms via the propositional parser.\n    \"\"\"\n    s = s.strip()\n    if not s:\n        raise ValueError(\"Cannot parse empty sentence\")\n\n    # Strip outer parens if they wrap the entire expression\n    if s.startswith(\"(\") and s.endswith(\")\"):\n        depth = 0\n        all_wrapped = True\n        for i, c in enumerate(s):\n            if c == \"(\":\n                depth += 1\n            elif c == \")\":\n                depth -= 1\n            if depth == 0 and i &lt; len(s) - 1:\n                all_wrapped = False\n                break\n        if all_wrapped:\n            return parse_rq_sentence(s[1:-1])\n\n    # --- Binary connectives at depth 0, lowest precedence first ---\n\n    # Implication (right-associative, lowest precedence)\n    depth = 0\n    for i in range(len(s)):\n        c = s[i]\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and s[i : i + 2] == \"-&gt;\":\n            left_str = s[:i].strip()\n            right_str = s[i + 2 :].strip()\n            if not left_str or not right_str:\n                raise ValueError(f\"Malformed implication in: {s!r}\")\n            return Sentence(\n                type=IMPL,\n                left=parse_sentence(left_str),\n                right=parse_sentence(right_str),\n            )\n\n    # Disjunction (left-associative) \u2014 find last '|' at depth 0\n    depth = 0\n    last_disj = -1\n    for i, c in enumerate(s):\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and c == \"|\":\n            last_disj = i\n    if last_disj &gt;= 0:\n        left_str = s[:last_disj].strip()\n        right_str = s[last_disj + 1 :].strip()\n        if not left_str or not right_str:\n            raise ValueError(f\"Malformed disjunction in: {s!r}\")\n        return Sentence(\n            type=DISJ,\n            left=parse_sentence(left_str),\n            right=parse_sentence(right_str),\n        )\n\n    # Conjunction (left-associative) \u2014 find last '&amp;' at depth 0\n    depth = 0\n    last_conj = -1\n    for i, c in enumerate(s):\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and c == \"&amp;\":\n            last_conj = i\n    if last_conj &gt;= 0:\n        left_str = s[:last_conj].strip()\n        right_str = s[last_conj + 1 :].strip()\n        if not left_str or not right_str:\n            raise ValueError(f\"Malformed conjunction in: {s!r}\")\n        return Sentence(\n            type=CONJ,\n            left=parse_sentence(left_str),\n            right=parse_sentence(right_str),\n        )\n\n    # Negation\n    if s.startswith(\"~\"):\n        sub_str = s[1:].strip()\n        if not sub_str:\n            raise ValueError(\"Negation with no operand\")\n        return Sentence(type=NEG, sub=parse_sentence(sub_str))\n\n    # --- RQ-specific atomic patterns ---\n\n    # ALL R.C(a) \u2014 universal restriction\n    m = _ALL_RE.match(s)\n    if m:\n        return RQSentence(\n            type=ALL_RESTRICT,\n            role=m.group(1),\n            concept=m.group(2),\n            individual=m.group(3),\n        )\n\n    # SOME R.C(a) \u2014 existential restriction\n    m = _SOME_RE.match(s)\n    if m:\n        return RQSentence(\n            type=SOME_RESTRICT,\n            role=m.group(1),\n            concept=m.group(2),\n            individual=m.group(3),\n        )\n\n    # Role assertion: R(a,b)\n    m = _ROLE_RE.match(s)\n    if m:\n        return RQSentence(\n            type=ATOM_ROLE,\n            role=m.group(1),\n            arg1=m.group(2),\n            arg2=m.group(3),\n        )\n\n    # Concept assertion: C(a)\n    m = _CONCEPT_RE.match(s)\n    if m:\n        return RQSentence(\n            type=ATOM_CONCEPT,\n            concept=m.group(1),\n            individual=m.group(2),\n        )\n\n    # Fall through to bare atom (propositional)\n    return Sentence(type=ATOM, name=s)\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.is_rq_atomic","title":"<code>is_rq_atomic(s)</code>","text":"<p>Return True if s is a concept assertion, role assertion, or bare atom.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def is_rq_atomic(s: str) -&gt; bool:\n    \"\"\"Return True if *s* is a concept assertion, role assertion, or bare atom.\"\"\"\n    parsed = parse_rq_sentence(s)\n    if isinstance(parsed, RQSentence):\n        return parsed.type in (ATOM_CONCEPT, ATOM_ROLE)\n    return parsed.type == ATOM\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.all_rq_atomic","title":"<code>all_rq_atomic(sentences)</code>","text":"<p>Return True if every sentence in sentences is RQ-atomic.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def all_rq_atomic(sentences: frozenset[str]) -&gt; bool:\n    \"\"\"Return True if every sentence in *sentences* is RQ-atomic.\"\"\"\n    return all(is_rq_atomic(s) for s in sentences)\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.make_concept_assertion","title":"<code>make_concept_assertion(concept, individual)</code>","text":"<p>Construct <code>C(a)</code> string.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def make_concept_assertion(concept: str, individual: str) -&gt; str:\n    \"\"\"Construct ``C(a)`` string.\"\"\"\n    return f\"{concept}({individual})\"\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.make_role_assertion","title":"<code>make_role_assertion(role, arg1, arg2)</code>","text":"<p>Construct <code>R(a,b)</code> string.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def make_role_assertion(role: str, arg1: str, arg2: str) -&gt; str:\n    \"\"\"Construct ``R(a,b)`` string.\"\"\"\n    return f\"{role}({arg1},{arg2})\"\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.find_role_triggers","title":"<code>find_role_triggers(gamma, role_name, subject)</code>","text":"<p>Find all individuals b such that <code>R(subject, b)</code> is in gamma.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def find_role_triggers(\n    gamma: frozenset[str], role_name: str, subject: str\n) -&gt; list[str]:\n    \"\"\"Find all individuals *b* such that ``R(subject, b)`` is in *gamma*.\"\"\"\n    triggers: list[str] = []\n    for s in gamma:\n        parsed = parse_rq_sentence(s)\n        if (\n            isinstance(parsed, RQSentence)\n            and parsed.type == ATOM_ROLE\n            and parsed.role == role_name\n            and parsed.arg1 == subject\n            and parsed.arg2 is not None\n        ):\n            triggers.append(parsed.arg2)\n    return triggers\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.collect_individuals","title":"<code>collect_individuals(sentences)</code>","text":"<p>Extract all individual names mentioned in a set of sentences.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def collect_individuals(sentences: frozenset[str]) -&gt; set[str]:\n    \"\"\"Extract all individual names mentioned in a set of sentences.\"\"\"\n    individuals: set[str] = set()\n    for s in sentences:\n        parsed = parse_rq_sentence(s)\n        if isinstance(parsed, RQSentence):\n            if parsed.type == ATOM_CONCEPT:\n                individuals.add(parsed.individual)  # type: ignore[arg-type]\n            elif parsed.type == ATOM_ROLE:\n                individuals.add(parsed.arg1)  # type: ignore[arg-type]\n                individuals.add(parsed.arg2)  # type: ignore[arg-type]\n            elif parsed.type in (ALL_RESTRICT, SOME_RESTRICT):\n                individuals.add(parsed.individual)  # type: ignore[arg-type]\n    return individuals\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.fresh_individual","title":"<code>fresh_individual(used, prefix='w')</code>","text":"<p>Generate a fresh individual name not in used.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def fresh_individual(used: set[str], prefix: str = \"w\") -&gt; str:\n    \"\"\"Generate a fresh individual name not in *used*.\"\"\"\n    i = 0\n    while f\"{prefix}{i}\" in used:\n        i += 1\n    return f\"{prefix}{i}\"\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.concept_label","title":"<code>concept_label(individual, sentences)</code>","text":"<p>Extract the concept label of an individual.</p> <p>The concept label is the set of concept names asserted of individual in sentences. Used for blocking: if a fresh individual's concept label is a subset of some existing individual's label, the fresh individual is blocked.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def concept_label(individual: str, sentences: frozenset[str]) -&gt; frozenset[str]:\n    \"\"\"Extract the concept label of an individual.\n\n    The concept label is the set of concept names asserted of *individual*\n    in *sentences*. Used for blocking: if a fresh individual's concept label\n    is a subset of some existing individual's label, the fresh individual is\n    blocked.\n    \"\"\"\n    labels: set[str] = set()\n    for s in sentences:\n        parsed = parse_rq_sentence(s)\n        if (\n            isinstance(parsed, RQSentence)\n            and parsed.type == ATOM_CONCEPT\n            and parsed.individual == individual\n        ):\n            labels.add(parsed.concept)  # type: ignore[arg-type]\n    return frozenset(labels)\n</code></pre>"},{"location":"api/rq-syntax/#pynmms.rq.syntax.find_blocking_individual","title":"<code>find_blocking_individual(fresh, gamma, delta, used)</code>","text":"<p>Check if any existing individual blocks the fresh individual.</p> <p>Fresh individual fresh is blocked by existing individual c if the concept label of fresh in the current context is a subset of the concept label of c. Returns the blocking individual or <code>None</code>.</p> Source code in <code>src/pynmms/rq/syntax.py</code> <pre><code>def find_blocking_individual(\n    fresh: str,\n    gamma: frozenset[str],\n    delta: frozenset[str],\n    used: set[str],\n) -&gt; str | None:\n    \"\"\"Check if any existing individual blocks the fresh individual.\n\n    Fresh individual *fresh* is blocked by existing individual *c* if the\n    concept label of *fresh* in the current context is a subset of the\n    concept label of *c*. Returns the blocking individual or ``None``.\n    \"\"\"\n    all_sentences = gamma | delta\n    fresh_label = concept_label(fresh, all_sentences)\n\n    for c in sorted(used):  # sorted for determinism\n        if c == fresh:\n            continue\n        c_label = concept_label(c, all_sentences)\n        if fresh_label &lt;= c_label:  # subset\n            return c\n    return None\n</code></pre>"},{"location":"api/syntax/","title":"Syntax","text":""},{"location":"api/syntax/#pynmms.syntax.Sentence","title":"<code>pynmms.syntax.Sentence</code>  <code>dataclass</code>","text":"<p>Immutable AST node for a propositional sentence.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>One of ATOM, NEG, CONJ, DISJ, IMPL.</p> <code>name</code> <code>str | None</code> <p>The atom name (only when type == ATOM).</p> <code>sub</code> <code>Sentence | None</code> <p>The sub-sentence (only when type == NEG).</p> <code>left</code> <code>Sentence | None</code> <p>Left operand (only when type in {CONJ, DISJ, IMPL}).</p> <code>right</code> <code>Sentence | None</code> <p>Right operand (only when type in {CONJ, DISJ, IMPL}).</p> Source code in <code>src/pynmms/syntax.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass Sentence:\n    \"\"\"Immutable AST node for a propositional sentence.\n\n    Attributes:\n        type: One of ATOM, NEG, CONJ, DISJ, IMPL.\n        name: The atom name (only when type == ATOM).\n        sub: The sub-sentence (only when type == NEG).\n        left: Left operand (only when type in {CONJ, DISJ, IMPL}).\n        right: Right operand (only when type in {CONJ, DISJ, IMPL}).\n    \"\"\"\n\n    type: str\n    name: str | None = None\n    sub: Sentence | None = None\n    left: Sentence | None = None\n    right: Sentence | None = None\n\n    def __str__(self) -&gt; str:\n        if self.type == ATOM:\n            return self.name  # type: ignore[return-value]\n        if self.type == NEG:\n            return f\"~{self.sub}\"\n        if self.type == CONJ:\n            return f\"({self.left} &amp; {self.right})\"\n        if self.type == DISJ:\n            return f\"({self.left} | {self.right})\"\n        if self.type == IMPL:\n            return f\"({self.left} -&gt; {self.right})\"\n        return f\"Sentence({self.type})\"  # pragma: no cover\n</code></pre>"},{"location":"api/syntax/#pynmms.syntax.parse_sentence","title":"<code>pynmms.syntax.parse_sentence(s)</code>","text":"<p>Parse a string into a propositional Sentence AST.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; parse_sentence(\"A\")\nSentence(type='atom', name='A', ...)\n&gt;&gt;&gt; parse_sentence(\"A -&gt; B\")\nSentence(type='impl', ..., left=Sentence(type='atom', name='A', ...),\n         right=Sentence(type='atom', name='B', ...))\n</code></pre> Source code in <code>src/pynmms/syntax.py</code> <pre><code>def parse_sentence(s: str) -&gt; Sentence:\n    \"\"\"Parse a string into a propositional Sentence AST.\n\n    Examples:\n        &gt;&gt;&gt; parse_sentence(\"A\")\n        Sentence(type='atom', name='A', ...)\n        &gt;&gt;&gt; parse_sentence(\"A -&gt; B\")\n        Sentence(type='impl', ..., left=Sentence(type='atom', name='A', ...),\n                 right=Sentence(type='atom', name='B', ...))\n    \"\"\"\n    s = s.strip()\n    if not s:\n        raise ValueError(\"Cannot parse empty sentence\")\n\n    # Strip outer parens if they wrap the entire expression\n    if s.startswith(\"(\") and s.endswith(\")\"):\n        depth = 0\n        all_wrapped = True\n        for i, c in enumerate(s):\n            if c == \"(\":\n                depth += 1\n            elif c == \")\":\n                depth -= 1\n            if depth == 0 and i &lt; len(s) - 1:\n                all_wrapped = False\n                break\n        if all_wrapped:\n            return parse_sentence(s[1:-1])\n\n    # --- Binary connectives at depth 0, lowest precedence first ---\n\n    # Implication (right-associative, lowest precedence)\n    # Scan left-to-right: first match gives right-associativity\n    depth = 0\n    for i in range(len(s)):\n        c = s[i]\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and s[i : i + 2] == \"-&gt;\":\n            left_str = s[:i].strip()\n            right_str = s[i + 2 :].strip()\n            if not left_str or not right_str:\n                raise ValueError(f\"Malformed implication in: {s!r}\")\n            return Sentence(\n                type=IMPL,\n                left=parse_sentence(left_str),\n                right=parse_sentence(right_str),\n            )\n\n    # Disjunction (left-associative) \u2014 find last '|' at depth 0\n    depth = 0\n    last_disj = -1\n    for i, c in enumerate(s):\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and c == \"|\":\n            last_disj = i\n    if last_disj &gt;= 0:\n        left_str = s[:last_disj].strip()\n        right_str = s[last_disj + 1 :].strip()\n        if not left_str or not right_str:\n            raise ValueError(f\"Malformed disjunction in: {s!r}\")\n        return Sentence(\n            type=DISJ,\n            left=parse_sentence(left_str),\n            right=parse_sentence(right_str),\n        )\n\n    # Conjunction (left-associative) \u2014 find last '&amp;' at depth 0\n    depth = 0\n    last_conj = -1\n    for i, c in enumerate(s):\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif depth == 0 and c == \"&amp;\":\n            last_conj = i\n    if last_conj &gt;= 0:\n        left_str = s[:last_conj].strip()\n        right_str = s[last_conj + 1 :].strip()\n        if not left_str or not right_str:\n            raise ValueError(f\"Malformed conjunction in: {s!r}\")\n        return Sentence(\n            type=CONJ,\n            left=parse_sentence(left_str),\n            right=parse_sentence(right_str),\n        )\n\n    # Negation\n    if s.startswith(\"~\"):\n        sub_str = s[1:].strip()\n        if not sub_str:\n            raise ValueError(\"Negation with no operand\")\n        return Sentence(type=NEG, sub=parse_sentence(sub_str))\n\n    # Bare atom\n    return Sentence(type=ATOM, name=s)\n</code></pre>"},{"location":"api/syntax/#pynmms.syntax.is_atomic","title":"<code>pynmms.syntax.is_atomic(s)</code>","text":"<p>Return True if s parses to a bare atom (no logical connectives).</p> Source code in <code>src/pynmms/syntax.py</code> <pre><code>def is_atomic(s: str) -&gt; bool:\n    \"\"\"Return True if *s* parses to a bare atom (no logical connectives).\"\"\"\n    return parse_sentence(s).type == ATOM\n</code></pre>"},{"location":"api/syntax/#pynmms.syntax.all_atomic","title":"<code>pynmms.syntax.all_atomic(sentences)</code>","text":"<p>Return True if every sentence in sentences is atomic.</p> Source code in <code>src/pynmms/syntax.py</code> <pre><code>def all_atomic(sentences: frozenset[str]) -&gt; bool:\n    \"\"\"Return True if every sentence in *sentences* is atomic.\"\"\"\n    return all(is_atomic(s) for s in sentences)\n</code></pre>"},{"location":"theory/nmms-calculus/","title":"The NMMS Calculus","text":"<p>This page describes the theoretical foundations of pyNMMS, following Hlobil &amp; Brandom (2025), Chapter 3: \"Introducing Logical Vocabulary.\"</p>"},{"location":"theory/nmms-calculus/#overview","title":"Overview","text":"<p>NMMS (Non-Monotonic Multi-Succedent) is a sequent calculus for codifying open reason relations \u2014 consequence relations where Monotonicity ([Weakening]) and Transitivity ([Mixed-Cut]) can fail.</p>"},{"location":"theory/nmms-calculus/#material-base-definition-1","title":"Material Base (Definition 1)","text":"<p>A material base B =  consists of: <ul> <li>An atomic language L_B</li> <li>A base consequence relation |~_B \u2286 P(L_B) x P(L_B)</li> </ul> <p>satisfying Containment: Gamma \u2229 Delta \u2260 \u2205 implies Gamma |~_B Delta.</p> <p>The base encodes defeasible material inferences among atomic sentences as axioms.</p>"},{"location":"theory/nmms-calculus/#logical-extension","title":"Logical Extension","text":"<p>The rules of NMMS extend |~_B to a consequence relation |~ over a logically extended language L (adding ~, -&gt;, &amp;, |). A sequent Gamma =&gt; Delta is derivable iff there is a proof tree whose leaves are all axioms (base sequents).</p>"},{"location":"theory/nmms-calculus/#structural-rules-absent","title":"Structural Rules (Absent)","text":"<p>NMMS omits two structural rules:</p> <ul> <li>[Weakening]: Gamma |~ Delta does NOT imply Gamma, A |~ Delta. Adding premises can defeat inferences.</li> <li>[Mixed-Cut]: Gamma |~ A, Delta and Gamma', A |~ Delta' does NOT imply Gamma, Gamma' |~ Delta, Delta'. Chaining good inferences can yield bad ones.</li> </ul>"},{"location":"theory/nmms-calculus/#propositional-rules","title":"Propositional Rules","text":"<p>All rules are Ketonen-style. Multi-premise rules include a third top sequent containing all active formulae from the other premises on the same sides. This compensates for the absence of structural contraction.</p>"},{"location":"theory/nmms-calculus/#left-rules","title":"Left Rules","text":"<p>[L~] Negation left:</p> <pre><code>    Gamma =&gt; Delta, A\n    -----------------\n    Gamma, ~A =&gt; Delta\n</code></pre> <p>[L-&gt;] Implication left (3 premises):</p> <pre><code>    Gamma =&gt; Delta, A     Gamma, B =&gt; Delta     Gamma, B =&gt; Delta, A\n    -----------------------------------------------------------------\n                      Gamma, A -&gt; B =&gt; Delta\n</code></pre> <p>[L&amp;] Conjunction left:</p> <pre><code>    Gamma, A, B =&gt; Delta\n    --------------------\n    Gamma, A &amp; B =&gt; Delta\n</code></pre> <p>[L|] Disjunction left (3 premises):</p> <pre><code>    Gamma, A =&gt; Delta     Gamma, B =&gt; Delta     Gamma, A, B =&gt; Delta\n    -----------------------------------------------------------------\n                      Gamma, A | B =&gt; Delta\n</code></pre>"},{"location":"theory/nmms-calculus/#right-rules","title":"Right Rules","text":"<p>[R~] Negation right:</p> <pre><code>    Gamma, A =&gt; Delta\n    -----------------\n    Gamma =&gt; Delta, ~A\n</code></pre> <p>[R-&gt;] Implication right:</p> <pre><code>    Gamma, A =&gt; Delta, B\n    --------------------\n    Gamma =&gt; Delta, A -&gt; B\n</code></pre> <p>[R&amp;] Conjunction right (3 premises):</p> <pre><code>    Gamma =&gt; Delta, A     Gamma =&gt; Delta, B     Gamma =&gt; Delta, A, B\n    -----------------------------------------------------------------\n                      Gamma =&gt; Delta, A &amp; B\n</code></pre> <p>[R|] Disjunction right:</p> <pre><code>    Gamma =&gt; Delta, A, B\n    --------------------\n    Gamma =&gt; Delta, A | B\n</code></pre>"},{"location":"theory/nmms-calculus/#critical-properties","title":"Critical Properties","text":""},{"location":"theory/nmms-calculus/#supraclassicality-fact-2","title":"Supraclassicality (Fact 2)","text":"<p>CL \u2286 |~ \u2014 all classically valid sequents are derivable when the base obeys Containment. The \"narrowly logical part\" (derivable from Containment alone) is exactly classical propositional logic.</p>"},{"location":"theory/nmms-calculus/#conservative-extension-fact-3-prop-26","title":"Conservative Extension (Fact 3 / Prop. 26)","text":"<p>If Gamma \u222a Delta \u2286 L_B, then Gamma |~ Delta iff Gamma |~_B Delta. Adding logical vocabulary does not change base-level reason relations.</p>"},{"location":"theory/nmms-calculus/#invertibility-prop-27","title":"Invertibility (Prop. 27)","text":"<p>All NMMS rules are invertible \u2014 the bottom sequent is derivable iff all top sequents are derivable.</p>"},{"location":"theory/nmms-calculus/#projection-theorem-7","title":"Projection (Theorem 7)","text":"<p>Every sequent Gamma =&gt; Delta in the extended language uniquely decomposes into a set of base-vocabulary sequents (AtomicImp) such that Gamma =&gt; Delta is derivable iff AtomicImp \u2286 |~_B.</p>"},{"location":"theory/nmms-calculus/#explicitation-conditions","title":"Explicitation Conditions","text":"<p>These biconditionals show how logical vocabulary \"makes explicit\" reason relations:</p> <ul> <li>DD (Deduction-Detachment): Gamma |~ A -&gt; B, Delta iff Gamma, A |~ B, Delta</li> <li>II (Incoherence-Incompatibility): Gamma |~ ~A, Delta iff Gamma, A |~ Delta</li> <li>AA (Antecedent-Adjunction): Gamma, A &amp; B |~ Delta iff Gamma, A, B |~ Delta</li> <li>SS (Succedent-Summation): Gamma |~ A | B, Delta iff Gamma |~ A, B, Delta</li> </ul>"},{"location":"theory/nmms-calculus/#references","title":"References","text":"<ul> <li>Hlobil, U. &amp; Brandom, R. B. (2025). Reasons for Logic, Logic for Reasons. Chapter 3: \"Introducing Logical Vocabulary.\"</li> </ul>"},{"location":"theory/rq-extension/","title":"Restricted Quantifier Extension","text":"<p>The <code>pynmms.rq</code> subpackage extends propositional NMMS with ALC-style restricted quantifiers (<code>ALL R.C</code>, <code>SOME R.C</code>), following the semantic framework of Hlobil (2025), \"First-Order Implication-Space Semantics.\"</p>"},{"location":"theory/rq-extension/#motivation","title":"Motivation","text":"<p>Standard unrestricted quantifier rules fail in nonmonotonic settings:</p> <ul> <li> <p>The <code>\u2200R</code> problem (Inf-5/Inf-6): Unrestricted <code>\u2200R</code> overgeneralizes from specific instances. If Shakespeare authored great works, <code>\u2200R</code> concludes everyone is an important author \u2014 generalizing over the entire domain rather than just authors.</p> </li> <li> <p>The <code>\u2200L</code> problem (Inf-7/Inf-8): Unrestricted <code>\u2200L</code> smuggles in defeating information via universal instantiation. If all bottles in the fridge are empty, <code>\u2200L</code> instantiates over all domain objects, bringing in information that defeats defeasible inferences.</p> </li> </ul> <p>Restricted quantifiers (<code>ALL R.C</code>, <code>SOME R.C</code>) avoid both problems by quantifying only over role successors <code>{b | R(a,b)}</code> rather than the full domain. This keeps the domain of quantification local to explicit role assertions in the proof context.</p>"},{"location":"theory/rq-extension/#syntax","title":"Syntax","text":"<pre><code>Individual:              alice, bob, carol, ...\nConcept assertion:       Human(alice)\nRole assertion:          hasChild(alice,bob)\nUniversal restriction:   ALL hasChild.Happy(alice)\n                         = \"all children of alice are Happy\"\nExistential restriction: SOME hasChild.Doctor(alice)\n                         = \"some child of alice is a Doctor\"\n</code></pre> <p>Propositional connectives (<code>~</code>, <code>&amp;</code>, <code>|</code>, <code>-&gt;</code>) work as in the base calculus and can combine with quantified sentences:</p> <pre><code>ALL hasChild.Happy(alice) -&gt; Happy(bob)\nALL hasChild.Happy(alice) | ~ALL hasChild.Happy(alice)\nALL hasChild.Happy(alice) &amp; ALL hasChild.Smart(alice)\n</code></pre>"},{"location":"theory/rq-extension/#the-four-quantifier-rules","title":"The Four Quantifier Rules","text":""},{"location":"theory/rq-extension/#lrc-universal-restriction-on-the-left","title":"[L\u2200R.C] \u2014 Universal restriction on the left","text":"<pre><code>\u0393, ALL R.C(a) \u21d2 \u0394  \u2190  \u0393, {C(b) | R(a,b) \u2208 \u0393} \u21d2 \u0394\n</code></pre> <p>Adjunction interpretation (OQ-1, option A): <code>ALL R.C(a)</code> as a premise behaves as a generalized conjunction over triggered instances. One subgoal adds all <code>C(b)</code> for known R-successors <code>b</code>.</p> <p>How it avoids the \u2200L problem: Instantiates only for triggered role successors present in <code>\u0393</code>, not the full domain. No hidden Weakening \u2014 no information enters the proof that wasn't already explicitly present as a role assertion.</p>"},{"location":"theory/rq-extension/#lrc-existential-restriction-on-the-left","title":"[L\u2203R.C] \u2014 Existential restriction on the left","text":"<pre><code>\u0393, SOME R.C(a) \u21d2 \u0394  \u2190  for all nonempty subsets S of {C(b) | R(a,b) \u2208 \u0393}:\n                          \u0393, S \u21d2 \u0394\n</code></pre> <p>Ketonen pattern: All <code>2^k - 1</code> nonempty subsets of triggered instances must independently prove the conclusion. This is the restricted analogue of Hlobil's power-symjunction for generalized disjunction.</p> <p>For binary <code>L\u2228</code> with <code>{A, B}</code>, this gives the familiar three top sequents: <code>{A}</code>, <code>{B}</code>, <code>{A,B}</code>. For <code>n</code> triggers, we need all <code>2^n - 1</code> nonempty subsets.</p>"},{"location":"theory/rq-extension/#rrc-existential-restriction-on-the-right","title":"[R\u2203R.C] \u2014 Existential restriction on the right","text":"<pre><code>\u0393 \u21d2 \u0394, SOME R.C(a)\n</code></pre> <p>Two strategies:</p> <ol> <li>Known witnesses: For each <code>b</code> with <code>R(a,b) \u2208 \u0393</code>, prove <code>\u0393 \u21d2 \u0394, C(b)</code>.</li> <li>Fresh canonical witness: Try <code>_w_{R}_{C}_{a}</code> with concept-label blocking (experimental).</li> </ol>"},{"location":"theory/rq-extension/#rrc-universal-restriction-on-the-right","title":"[R\u2200R.C] \u2014 Universal restriction on the right","text":"<pre><code>\u0393 \u21d2 \u0394, ALL R.C(a)  \u2190  \u0393, R(a,b) \u21d2 \u0394, C(b)   (b fresh eigenvariable)\n</code></pre> <p>How it avoids the \u2200R problem: The eigenvariable represents an arbitrary role successor, not an arbitrary domain element. We only need to show <code>C(b)</code> holds for an arbitrary R-successor of <code>a</code>, not for every object in the domain.</p>"},{"location":"theory/rq-extension/#design-decisions","title":"Design Decisions","text":""},{"location":"theory/rq-extension/#oq-1-adjunction-vs-power-symjunction-for-lrc","title":"OQ-1: Adjunction vs. Power-Symjunction for [L\u2200R.C]","text":"<p>Hlobil's semantic clause for <code>\u2200</code> uses power-symjunction (Def. 16), not adjunction. The current implementation uses adjunction (option A): one subgoal adding all triggered instances simultaneously.</p> <p>Arguments for adjunction:</p> <ol> <li>Matches propositional <code>[L\u2227]</code> pattern (1 subgoal = multiplicative)</li> <li>Consistent with classical ALC tableau rules</li> <li>Avoids exponential branching (already present in <code>[L\u2203R.C]</code>)</li> <li>The restricted domain mitigates the <code>\u2200L</code> problem that motivated power-symjunction</li> <li>All 10 legacy demo scenarios pass with this interpretation</li> </ol> <p>This is documented as a design choice pending theoretical analysis.</p>"},{"location":"theory/rq-extension/#oq-2-blocking-soundness","title":"OQ-2: Blocking Soundness","text":"<p>Experimental</p> <p>Concept-label subset blocking is an experimental conjecture adapted from classical ALC tableau procedures.</p> <p>Fresh witness <code>b</code> is blocked if <code>concept_label(b) \u2286 concept_label(c)</code> for some existing individual <code>c</code>. This is conjectured to be sound for NMMS because nonmonotonicity arises from the material base (exact match), not from logical rules.</p>"},{"location":"theory/rq-extension/#oq-3-empty-trigger-handling","title":"OQ-3: Empty Trigger Handling","text":"<ul> <li><code>ALL R.C(a)</code> with no triggers: vacuously true as premise, treated as inert (falls through)</li> <li><code>SOME R.C(a)</code> with no triggers: treated as inert (safe, potentially incomplete)</li> </ul>"},{"location":"theory/rq-extension/#preserved-properties","title":"Preserved Properties","text":"<p>All five constraints from the propositional calculus are preserved:</p> Property Description Status MOF Nonmonotonicity \u2014 adding premises defeats inferences Preserved SCL Supraclassicality \u2014 all classically valid sequents derivable Preserved DDT Deduction-detachment theorem Preserved DS Disjunction simplification (Ketonen pattern) Preserved LC Left conjunction is multiplicative Preserved (with adjunction, OQ-1)"},{"location":"theory/rq-extension/#lazy-schema-evaluation","title":"Lazy Schema Evaluation","text":"<p>Quantified commitments are stored as schemas and evaluated lazily during <code>is_axiom</code> checks. No eager grounding over all known individuals.</p> <ul> <li>Storage: <code>O(k + m)</code> schemas, not <code>O(n \u00d7 (k + m))</code> ground entries</li> <li>Adding individuals: <code>O(1)</code>, no schema re-expansion needed</li> <li>Query time: Schemas matched against concrete individuals in each sequent</li> </ul>"},{"location":"theory/rq-extension/#references","title":"References","text":"<ul> <li>Hlobil (2025), \"First-Order Implication-Space Semantics,\" \u00a72 (Inf-5/6/7/8) and \u00a73 (power-symjunction, Proposition 20)</li> <li>Hlobil &amp; Brandom (2025), Ch. 3, \"Introducing Logical Vocabulary\"</li> </ul>"},{"location":"tutorial/cli-usage/","title":"CLI Usage","text":""},{"location":"tutorial/cli-usage/#overview","title":"Overview","text":"<p>pyNMMS provides the <code>pynmms</code> command with three subcommands:</p> <pre><code>pynmms tell   # Add atoms or consequences to a base\npynmms ask    # Query derivability\npynmms repl   # Interactive REPL\n</code></pre>"},{"location":"tutorial/cli-usage/#pynmms-tell","title":"<code>pynmms tell</code>","text":"<p>Add atoms or consequences to a JSON base file.</p> <pre><code># Create a new base and add a consequence\npynmms tell -b base.json --create \"A |~ B\"\n\n# Add more consequences (base file must exist)\npynmms tell -b base.json \"B |~ C\"\n\n# Add atoms\npynmms tell -b base.json \"atom X\"\n</code></pre>"},{"location":"tutorial/cli-usage/#syntax","title":"Syntax","text":"<ul> <li>Consequence: <code>A |~ B</code> or <code>A, B |~ C, D</code> (comma-separated)</li> <li>Atom: <code>atom X</code></li> </ul>"},{"location":"tutorial/cli-usage/#pynmms-ask","title":"<code>pynmms ask</code>","text":"<p>Query whether a sequent is derivable.</p> <pre><code>pynmms ask -b base.json \"A =&gt; B\"\n# Output: DERIVABLE\n\npynmms ask -b base.json \"A =&gt; C\"\n# Output: NOT DERIVABLE\n</code></pre>"},{"location":"tutorial/cli-usage/#options","title":"Options","text":"<ul> <li><code>--trace</code>: Print the proof trace</li> <li><code>--max-depth N</code>: Set the maximum proof depth (default: 25)</li> </ul> <pre><code>pynmms ask -b base.json --trace \"=&gt; A -&gt; B\"\n# Output:\n# DERIVABLE\n#\n# Proof trace:\n#   [R\u2192] on A -&gt; B\n#     AXIOM: A =&gt; B\n#\n# Depth reached: 1\n# Cache hits: 0\n</code></pre>"},{"location":"tutorial/cli-usage/#pynmms-repl","title":"<code>pynmms repl</code>","text":"<p>Interactive REPL for exploring reason relations.</p> <pre><code>pynmms repl\npynmms repl -b base.json  # Load existing base\n</code></pre>"},{"location":"tutorial/cli-usage/#repl-commands","title":"REPL Commands","text":"Command Description <code>tell A \\|~ B</code> Add a consequence <code>tell atom A</code> Add an atom <code>ask A =&gt; B</code> Query derivability <code>show</code> Display the current base <code>trace on/off</code> Toggle proof trace display <code>save &lt;file&gt;</code> Save base to JSON <code>load &lt;file&gt;</code> Load base from JSON <code>help</code> Show available commands <code>quit</code> Exit the REPL"},{"location":"tutorial/cli-usage/#example-session","title":"Example Session","text":"<pre><code>$ pynmms repl\nStarting with empty base.\npyNMMS REPL. Type 'help' for commands.\n\npynmms&gt; tell A |~ B\nAdded: {'A'} |~ {'B'}\npynmms&gt; tell B |~ C\nAdded: {'B'} |~ {'C'}\npynmms&gt; ask A =&gt; B\nDERIVABLE\npynmms&gt; ask A =&gt; C\nNOT DERIVABLE\npynmms&gt; trace on\nTrace: ON\npynmms&gt; ask =&gt; A -&gt; B\nDERIVABLE\n  [R\u2192] on A -&gt; B\n    AXIOM: A =&gt; B\n  Depth: 1, Cache hits: 0\npynmms&gt; save mybase.json\nSaved to mybase.json\npynmms&gt; quit\n</code></pre>"},{"location":"tutorial/concepts/","title":"Key Concepts","text":""},{"location":"tutorial/concepts/#material-bases","title":"Material Bases","text":"<p>A material base B =  consists of: <ul> <li>L_B: An atomic language \u2014 a set of atomic sentence strings (e.g., <code>\"rain\"</code>, <code>\"wet_ground\"</code>)</li> <li>|~_B: A base consequence relation \u2014 a set of sequents (Gamma, Delta) where Gamma and Delta are sets of atomic sentences</li> </ul> <p>The base encodes defeasible material inferences: reasoning patterns that hold in normal circumstances but can be overridden by additional information.</p>"},{"location":"tutorial/concepts/#containment-axiom","title":"Containment Axiom","text":"<p>Every material base automatically satisfies Containment: if Gamma and Delta share any element (Gamma \u2229 Delta \u2260 \u2205), then Gamma |~_B Delta. This is the analogue of the identity axiom in classical logic.</p>"},{"location":"tutorial/concepts/#exact-match-no-weakening","title":"Exact Match (No Weakening)","text":"<p>Base consequences require exact syntactic match. If the base contains <code>{A} |~ {B}</code>, then <code>{A, C} |~ {B}</code> is not an axiom. This is what makes the system nonmonotonic \u2014 extra premises can defeat inferences.</p>"},{"location":"tutorial/concepts/#sequents","title":"Sequents","text":"<p>A sequent Gamma =&gt; Delta represents a reason relation: the sentences in Gamma (the antecedent) provide reason for at least one of the sentences in Delta (the succedent).</p> <ul> <li>Multi-succedent: Delta can contain multiple sentences. <code>Gamma =&gt; A, B</code> means \"Gamma provides reason for A-or-B.\"</li> <li>Empty antecedent: <code>=&gt; A</code> means A is unconditionally assertable.</li> <li>Empty succedent: <code>A =&gt;</code> means A is incoherent (leads to nothing).</li> </ul>"},{"location":"tutorial/concepts/#nonmonotonicity","title":"Nonmonotonicity","text":"<p>In NMMS, adding premises can defeat inferences. If <code>{rain} |~ {wet_ground}</code> but the base has no consequence from <code>{rain, covered}</code>, then:</p> <ul> <li><code>rain =&gt; wet_ground</code> is derivable</li> <li><code>rain, covered =&gt; wet_ground</code> is not derivable</li> </ul> <p>This models the everyday pattern: rain normally makes the ground wet, but if the ground is covered, the inference is defeated.</p>"},{"location":"tutorial/concepts/#nontransitivity","title":"Nontransitivity","text":"<p>NMMS also lacks Mixed-Cut (the structural rule for transitivity). Even if <code>A |~ B</code> and <code>B |~ C</code>, it does not follow that <code>A |~ C</code>. Each inference step must be independently justified by the base.</p>"},{"location":"tutorial/concepts/#supraclassicality","title":"Supraclassicality","text":"<p>Despite lacking Weakening and Mixed-Cut, NMMS is supraclassical: all classically valid sequents are derivable. The law of excluded middle (<code>=&gt; A | ~A</code>), double negation elimination (<code>~~A =&gt; A</code>), and all classical tautologies hold.</p>"},{"location":"tutorial/concepts/#explicitation-conditions","title":"Explicitation Conditions","text":"<p>The logical connectives \"make explicit\" reason relations through these biconditionals:</p> <ul> <li>DD (Deduction-Detachment): <code>Gamma |~ A -&gt; B, Delta</code> iff <code>Gamma, A |~ B, Delta</code></li> <li>II (Incoherence-Incompatibility): <code>Gamma |~ ~A, Delta</code> iff <code>Gamma, A |~ Delta</code></li> <li>AA (Antecedent-Adjunction): <code>Gamma, A &amp; B |~ Delta</code> iff <code>Gamma, A, B |~ Delta</code></li> <li>SS (Succedent-Summation): <code>Gamma |~ A | B, Delta</code> iff <code>Gamma |~ A, B, Delta</code></li> </ul>"},{"location":"tutorial/material-bases/","title":"Material Bases","text":""},{"location":"tutorial/material-bases/#creating-a-base","title":"Creating a Base","text":""},{"location":"tutorial/material-bases/#via-python-api","title":"Via Python API","text":"<pre><code>from pynmms import MaterialBase\n\n# From constructor\nbase = MaterialBase(\n    language={\"A\", \"B\", \"C\"},\n    consequences={\n        (frozenset({\"A\"}), frozenset({\"B\"})),\n        (frozenset({\"B\"}), frozenset({\"C\"})),\n    },\n)\n\n# Incrementally\nbase = MaterialBase()\nbase.add_atom(\"A\")\nbase.add_atom(\"B\")\nbase.add_consequence(frozenset({\"A\"}), frozenset({\"B\"}))\n</code></pre>"},{"location":"tutorial/material-bases/#via-cli","title":"Via CLI","text":"<pre><code>pynmms tell -b mybase.json --create \"atom A\"\npynmms tell -b mybase.json \"atom B\"\npynmms tell -b mybase.json \"A |~ B\"\n</code></pre>"},{"location":"tutorial/material-bases/#checking-axioms","title":"Checking Axioms","text":"<p>The <code>is_axiom</code> method checks whether a sequent is an axiom of the base:</p> <pre><code>base.is_axiom(frozenset({\"A\"}), frozenset({\"A\"}))  # True (Containment)\nbase.is_axiom(frozenset({\"A\"}), frozenset({\"B\"}))  # True (base consequence)\nbase.is_axiom(frozenset({\"A\", \"X\"}), frozenset({\"B\"}))  # False (no weakening)\n</code></pre>"},{"location":"tutorial/material-bases/#serialization","title":"Serialization","text":"<p>Bases can be saved to and loaded from JSON:</p> <pre><code># Save\nbase.to_file(\"mybase.json\")\n\n# Load\nbase = MaterialBase.from_file(\"mybase.json\")\n\n# Dict round-trip\ndata = base.to_dict()\nbase = MaterialBase.from_dict(data)\n</code></pre>"},{"location":"tutorial/material-bases/#json-format","title":"JSON Format","text":"<pre><code>{\n  \"language\": [\"A\", \"B\", \"C\"],\n  \"consequences\": [\n    {\"antecedent\": [\"A\"], \"consequent\": [\"B\"]},\n    {\"antecedent\": [\"B\"], \"consequent\": [\"C\"]}\n  ]\n}\n</code></pre>"},{"location":"tutorial/material-bases/#validation","title":"Validation","text":"<p>The base enforces that all sentences are atomic:</p> <pre><code># This raises ValueError:\nMaterialBase(language={\"~A\"})  # Negation is not atomic\nMaterialBase(consequences={(frozenset({\"A -&gt; B\"}), frozenset({\"C\"}))})  # Implication is not atomic\n</code></pre>"},{"location":"tutorial/proof-search/","title":"Proof Search","text":""},{"location":"tutorial/proof-search/#using-the-reasoner","title":"Using the Reasoner","text":"<pre><code>from pynmms import MaterialBase, NMMSReasoner\n\nbase = MaterialBase(\n    language={\"A\", \"B\"},\n    consequences={(frozenset({\"A\"}), frozenset({\"B\"}))},\n)\nreasoner = NMMSReasoner(base, max_depth=25)\n</code></pre>"},{"location":"tutorial/proof-search/#derives-full-result","title":"<code>derives()</code> \u2014 Full Result","text":"<pre><code>result = reasoner.derives(frozenset({\"A\"}), frozenset({\"B\"}))\nprint(result.derivable)      # True\nprint(result.trace)          # ['AXIOM: A =&gt; B']\nprint(result.depth_reached)  # 0\nprint(result.cache_hits)     # 0\n</code></pre>"},{"location":"tutorial/proof-search/#query-boolean-only","title":"<code>query()</code> \u2014 Boolean Only","text":"<pre><code>reasoner.query(frozenset({\"A\"}), frozenset({\"B\"}))  # True\n</code></pre>"},{"location":"tutorial/proof-search/#reading-proof-traces","title":"Reading Proof Traces","text":"<p>The trace records every rule application and axiom closure:</p> <pre><code>result = reasoner.derives(frozenset(), frozenset({\"A -&gt; B\"}))\nfor line in result.trace:\n    print(line)\n</code></pre> <p>Output: <pre><code>[R\u2192] on A -&gt; B\n  AXIOM: A =&gt; B\n</code></pre></p> <p>Trace entries include: - <code>AXIOM: Gamma =&gt; Delta</code> \u2014 leaf of the proof tree (base axiom or containment) - <code>[L\u00ac] on ~A</code> \u2014 left negation rule applied - <code>[L\u2192] on A -&gt; B</code> \u2014 left implication rule (3 premises) - <code>[L\u2227] on A &amp; B</code> \u2014 left conjunction rule - <code>[L\u2228] on A | B</code> \u2014 left disjunction rule (3 premises, Ketonen pattern) - <code>[R\u00ac] on ~A</code> \u2014 right negation rule - <code>[R\u2192] on A -&gt; B</code> \u2014 right implication rule - <code>[R\u2227] on A &amp; B</code> \u2014 right conjunction rule (3 premises, Ketonen pattern) - <code>[R\u2228] on A | B</code> \u2014 right disjunction rule - <code>FAIL: Gamma =&gt; Delta</code> \u2014 no rule could close this branch - <code>DEPTH LIMIT</code> \u2014 maximum proof depth exceeded</p>"},{"location":"tutorial/proof-search/#depth-limit","title":"Depth Limit","text":"<p>The <code>max_depth</code> parameter (default 25) prevents infinite proof search:</p> <pre><code>reasoner = NMMSReasoner(base, max_depth=10)\n</code></pre> <p>If the depth limit is reached, the proof search returns <code>False</code> for that branch.</p>"},{"location":"tutorial/proof-search/#memoization","title":"Memoization","text":"<p>The reasoner uses memoization to avoid re-proving identical subgoals. The <code>cache_hits</code> field in <code>ProofResult</code> reports how many times a cached result was reused.</p>"},{"location":"tutorial/rq-tutorial/","title":"Restricted Quantifiers Tutorial","text":"<p>This tutorial shows how to use the <code>pynmms.rq</code> subpackage for reasoning with restricted quantifiers.</p>"},{"location":"tutorial/rq-tutorial/#building-an-rq-material-base","title":"Building an RQ Material Base","text":"<pre><code>from pynmms.rq import RQMaterialBase\n\n# Create a base with concept and role assertions\nbase = RQMaterialBase(\n    language={\n        \"hasChild(alice,bob)\", \"hasChild(alice,carol)\",\n        \"Happy(bob)\", \"Doctor(carol)\",\n    },\n    consequences={\n        (frozenset({\"hasChild(alice,bob)\", \"Doctor(bob)\"}),\n         frozenset({\"ParentOfDoctor(alice)\"})),\n        (frozenset({\"hasChild(alice,carol)\", \"Doctor(carol)\"}),\n         frozenset({\"ParentOfDoctor(alice)\"})),\n    },\n)\n</code></pre>"},{"location":"tutorial/rq-tutorial/#querying-with-quantifiers","title":"Querying with Quantifiers","text":"<pre><code>from pynmms.rq import NMMSRQReasoner\n\nr = NMMSRQReasoner(base, max_depth=20)\n\n# ALL hasChild.Doctor(alice) with trigger bob =&gt; ParentOfDoctor(alice)\nr.query(\n    frozenset({\"ALL hasChild.Doctor(alice)\", \"hasChild(alice,bob)\"}),\n    frozenset({\"ParentOfDoctor(alice)\"}),\n)  # True\n\n# SOME hasChild.Doctor(alice) with known witness carol\nr.query(\n    frozenset({\"hasChild(alice,carol)\", \"Doctor(carol)\"}),\n    frozenset({\"SOME hasChild.Doctor(alice)\"}),\n)  # True\n</code></pre>"},{"location":"tutorial/rq-tutorial/#nonmonotonicity-with-quantifiers","title":"Nonmonotonicity with Quantifiers","text":"<pre><code>base = RQMaterialBase(\n    consequences={\n        (frozenset({\"hasChild(alice,bob)\", \"Happy(bob)\"}),\n         frozenset({\"ParentHappy(alice)\"})),\n    },\n)\nr = NMMSRQReasoner(base, max_depth=15)\n\n# Good inference\nr.query(\n    frozenset({\"hasChild(alice,bob)\", \"Happy(bob)\"}),\n    frozenset({\"ParentHappy(alice)\"}),\n)  # True\n\n# Defeated by ALL hasChild.Grumpy \u2014 adds Grumpy(bob) to premises\nr.query(\n    frozenset({\n        \"hasChild(alice,bob)\", \"Happy(bob)\",\n        \"ALL hasChild.Grumpy(alice)\",\n    }),\n    frozenset({\"ParentHappy(alice)\"}),\n)  # False\n</code></pre>"},{"location":"tutorial/rq-tutorial/#using-schemas","title":"Using Schemas","text":"<pre><code>from pynmms.rq import RQMaterialBase, NMMSRQReasoner\n\nbase = RQMaterialBase(language={\"hasSymptom(patient,chestPain)\"})\n\n# Register a concept schema (lazy \u2014 no eager grounding)\nbase.register_concept_schema(\"hasSymptom\", \"patient\", \"Serious\")\n\n# Register an inference schema\nbase.register_inference_schema(\n    \"hasSymptom\", \"patient\", \"Serious\",\n    {\"HeartAttack(patient)\"},\n)\n\nr = NMMSRQReasoner(base, max_depth=15)\n\n# Schema fires lazily\nr.query(\n    frozenset({\"hasSymptom(patient,chestPain)\", \"Serious(chestPain)\"}),\n    frozenset({\"HeartAttack(patient)\"}),\n)  # True\n\n# Add new individual \u2014 schema works without re-grounding\nbase.add_individual(\"hasSymptom\", \"patient\", \"headache\")\nr2 = NMMSRQReasoner(base, max_depth=15)\nr2.query(\n    frozenset({\"hasSymptom(patient,headache)\", \"Serious(headache)\"}),\n    frozenset({\"HeartAttack(patient)\"}),\n)  # True\n</code></pre>"},{"location":"tutorial/rq-tutorial/#using-the-commitmentstore","title":"Using the CommitmentStore","text":"<pre><code>from pynmms.rq import CommitmentStore, NMMSRQReasoner\n\ncs = CommitmentStore()\ncs.add_assertion(\"hasSymptom(patient,chestPain)\")\ncs.commit_universal(\n    \"serious symptoms\",\n    \"hasSymptom\", \"patient\",\n    \"Serious\", \"HeartAttack\",\n)\n\nbase = cs.compile()\nr = NMMSRQReasoner(base, max_depth=15)\n</code></pre>"},{"location":"tutorial/rq-tutorial/#cli-usage-with-rq","title":"CLI Usage with <code>--rq</code>","text":"<pre><code># Add RQ atoms\npynmms tell -b rq_base.json --create --rq \"atom hasChild(alice,bob)\"\npynmms tell -b rq_base.json --rq \"hasChild(alice,bob), Doctor(bob) |~ ParentOfDoctor(alice)\"\n\n# Query\npynmms ask -b rq_base.json --rq \"ALL hasChild.Doctor(alice), hasChild(alice,bob) =&gt; ParentOfDoctor(alice)\"\npynmms ask -b rq_base.json --rq --trace \"hasChild(alice,bob), Doctor(bob) =&gt; SOME hasChild.Doctor(alice)\"\n\n# Interactive REPL\npynmms repl --rq\n</code></pre>"},{"location":"tutorial/rq-tutorial/#rq-repl-commands","title":"RQ REPL commands","text":"<pre><code>pynmms[rq]&gt; tell atom hasChild(alice,bob)\npynmms[rq]&gt; tell Happy(alice) |~ Good(alice)\npynmms[rq]&gt; tell schema concept hasChild alice Happy\npynmms[rq]&gt; tell schema inference hasChild alice Serious HeartAttack\npynmms[rq]&gt; ask ALL hasChild.Happy(alice), hasChild(alice,bob) =&gt; Happy(bob)\npynmms[rq]&gt; show schemas\npynmms[rq]&gt; show individuals\n</code></pre>"}]}